{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtvafqSbLIZB",
        "outputId": "8f9d98a0-041e-4c5c-c446-868960199040"
      },
      "outputs": [],
      "source": [
        "# prompt: mount google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOd-RYcFqQHf",
        "outputId": "6d0afcda-c19b-4395-e5ef-72668573906f"
      },
      "outputs": [],
      "source": [
        "!pip install optuna\n",
        "!pip install pytorch-lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4RGB22oqfCS",
        "outputId": "4e8ca33b-1597-4276-eace-87d4e997fc1f"
      },
      "outputs": [],
      "source": [
        "!pip install optuna-integration[pytorch_lightning]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PAkG033IWyi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from collections import defaultdict, Counter\n",
        "import warnings\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "import optuna\n",
        "from optuna.integration import PyTorchLightningPruningCallback\n",
        "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE\n",
        "from imblearn.combine import SMOTEENN, SMOTETomek\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITw2XthwqGtz"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def load_and_clean_data(vrnet_csv_path: str, vrwalking_csv_path: str):\n",
        "    \"\"\"Load and clean CSV data with proper type handling\"\"\"\n",
        "\n",
        "    print(\"Loading and cleaning data...\")\n",
        "\n",
        "    # Load VR.net data\n",
        "    print(f\"Loading VR.net data: {vrnet_csv_path}\")\n",
        "    vrnet_df = pd.read_csv(vrnet_csv_path)\n",
        "    print(f\"  Original shape: {vrnet_df.shape}\")\n",
        "\n",
        "    # Load VRWalking data\n",
        "    print(f\"Loading VRWalking data: {vrwalking_csv_path}\")\n",
        "    vrwalking_df = pd.read_csv(vrwalking_csv_path)\n",
        "    print(f\"  Original shape: {vrwalking_df.shape}\")\n",
        "\n",
        "    # Standardize FMS column names\n",
        "    if 'fms_label' in vrnet_df.columns:\n",
        "        vrnet_df['fms_score'] = pd.to_numeric(vrnet_df['fms_label'], errors='coerce')\n",
        "        print(\"  ✓ VR.net: Using 'fms_label' column\")\n",
        "    elif 'fms' in vrnet_df.columns:\n",
        "        vrnet_df['fms_score'] = pd.to_numeric(vrnet_df['fms'], errors='coerce')\n",
        "        print(\"  ✓ VR.net: Using 'fms' column\")\n",
        "    else:\n",
        "        print(\"  ⚠️  VR.net: No FMS column found\")\n",
        "\n",
        "    if 'fms' in vrwalking_df.columns:\n",
        "        vrwalking_df['fms_score'] = pd.to_numeric(vrwalking_df['fms'], errors='coerce')\n",
        "        print(\"  ✓ VRWalking: Using 'fms' column\")\n",
        "    elif 'fms_label' in vrwalking_df.columns:\n",
        "        vrwalking_df['fms_score'] = pd.to_numeric(vrwalking_df['fms_label'], errors='coerce')\n",
        "        print(\"  ✓ VRWalking: Using 'fms_label' column\")\n",
        "    else:\n",
        "        print(\"  ⚠️  VRWalking: No FMS column found\")\n",
        "\n",
        "    # Add dataset identifiers\n",
        "    vrnet_df['dataset'] = 'vrnet'\n",
        "    vrwalking_df['dataset'] = 'vrwalking'\n",
        "\n",
        "    # Clean and convert data types\n",
        "    vrnet_df = clean_dataframe(vrnet_df, 'VR.net')\n",
        "    vrwalking_df = clean_dataframe(vrwalking_df, 'VRWalking')\n",
        "\n",
        "    return vrnet_df, vrwalking_df\n",
        "\n",
        "def parse_tuple_string(value):\n",
        "    \"\"\"Parse tuple-like strings into numeric values\"\"\"\n",
        "    if pd.isna(value) or value == '':\n",
        "        return []\n",
        "\n",
        "    if isinstance(value, str):\n",
        "        # Handle different tuple formats\n",
        "        value = value.strip()\n",
        "        if value.startswith('(') and value.endswith(')'):\n",
        "            # Remove parentheses\n",
        "            value = value[1:-1]\n",
        "\n",
        "        # Split by comma and convert to float\n",
        "        try:\n",
        "            parts = [float(x.strip()) for x in value.split(',')]\n",
        "            return parts\n",
        "        except:\n",
        "            return []\n",
        "    elif isinstance(value, (list, tuple)):\n",
        "        try:\n",
        "            return [float(x) for x in value]\n",
        "        except:\n",
        "            return []\n",
        "    else:\n",
        "        try:\n",
        "            return [float(value)]\n",
        "        except:\n",
        "            return []\n",
        "\n",
        "def clean_dataframe(df: pd.DataFrame, dataset_name: str) -> pd.DataFrame:\n",
        "    \"\"\"Clean dataframe with proper type conversion\"\"\"\n",
        "\n",
        "    print(f\"Cleaning {dataset_name} data...\")\n",
        "\n",
        "    # Identify metadata columns\n",
        "    metadata_cols = {\n",
        "        'participant_id', 'timestamp', 'fms', 'fms_label', 'fms_score',\n",
        "        'segment_id', 'dataset', 'folder_name', 'frame'\n",
        "    }\n",
        "\n",
        "    # Clean each column\n",
        "    for col in df.columns:\n",
        "        if col in metadata_cols:\n",
        "            # Handle metadata columns\n",
        "            if col in ['timestamp', 'segment_id', 'frame']:\n",
        "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "            elif col == 'participant_id':\n",
        "                df[col] = df[col].astype(str)\n",
        "            continue\n",
        "\n",
        "        # Handle feature columns\n",
        "        if col in df.columns:\n",
        "            # Check if column contains tuple-like strings\n",
        "            sample_values = df[col].dropna().head(10)\n",
        "\n",
        "            has_tuples = False\n",
        "            for val in sample_values:\n",
        "                if isinstance(val, str) and ('(' in str(val) or ',' in str(val)):\n",
        "                    has_tuples = True\n",
        "                    break\n",
        "\n",
        "            if has_tuples:\n",
        "                # Parse tuple strings into separate columns\n",
        "                print(f\"  Parsing tuple column: {col}\")\n",
        "                parsed_values = df[col].apply(parse_tuple_string)\n",
        "\n",
        "                # Find maximum tuple length\n",
        "                max_len = max([len(val) for val in parsed_values if len(val) > 0], default=1)\n",
        "\n",
        "                # Create separate columns for each tuple element\n",
        "                for i in range(max_len):\n",
        "                    new_col = f\"{col}_{i}\"\n",
        "                    df[new_col] = [val[i] if i < len(val) else np.nan for val in parsed_values]\n",
        "                    df[new_col] = pd.to_numeric(df[new_col], errors='coerce')\n",
        "\n",
        "                # Drop original tuple column\n",
        "                df = df.drop(columns=[col])\n",
        "            else:\n",
        "                # Convert to numeric\n",
        "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    print(f\"  Cleaned shape: {df.shape}\")\n",
        "    print(f\"  FMS score range: {df['fms_score'].min():.2f} - {df['fms_score'].max():.2f}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "class EnhancedTimeSeriesProcessor:\n",
        "    \"\"\"Enhanced processor with outlier removal, data balancing, and contextual features\"\"\"\n",
        "\n",
        "    def __init__(self, window_size: int = 60, overlap: float = 0.5):\n",
        "        self.window_size = window_size\n",
        "        self.overlap = overlap\n",
        "        self.scaler = RobustScaler()\n",
        "        self.outlier_detector = IsolationForest(contamination=0.1, random_state=42)\n",
        "\n",
        "    def identify_contextual_features(self, df: pd.DataFrame) -> Dict[str, List[str]]:\n",
        "        \"\"\"Identify contextual features mentioned as highly correlated with FMS\"\"\"\n",
        "\n",
        "        contextual_features = {\n",
        "            'timing_features': [],\n",
        "            'frame_features': [],\n",
        "            'eye_features': [],\n",
        "            'spatial_features': [],\n",
        "            'movement_features': []\n",
        "        }\n",
        "\n",
        "        # Search for contextual features (case insensitive)\n",
        "        for col in df.columns:\n",
        "            col_lower = col.lower()\n",
        "            if any(keyword in col_lower for keyword in ['eyeframe', 'eye_frame', 'eye']):\n",
        "                contextual_features['eye_features'].append(col)\n",
        "            elif any(keyword in col_lower for keyword in ['vivetiming', 'vive_timing', 'timing']):\n",
        "                contextual_features['timing_features'].append(col)\n",
        "            elif any(keyword in col_lower for keyword in ['frame', 'timestamp']):\n",
        "                contextual_features['frame_features'].append(col)\n",
        "            elif any(keyword in col_lower for keyword in ['position', 'pos', 'location', 'x', 'y', 'z']):\n",
        "                contextual_features['spatial_features'].append(col)\n",
        "            elif any(keyword in col_lower for keyword in ['velocity', 'vel', 'speed', 'acceleration', 'accel']):\n",
        "                contextual_features['movement_features'].append(col)\n",
        "\n",
        "        return contextual_features\n",
        "\n",
        "    def remove_outliers(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Remove outliers using Isolation Forest and statistical methods\"\"\"\n",
        "\n",
        "        print(\"Removing outliers...\")\n",
        "        original_len = len(df)\n",
        "\n",
        "        # Remove extreme FMS outliers (outside reasonable range)\n",
        "        df = df[(df['fms_score'] >= 1) & (df['fms_score'] <= 10)]\n",
        "\n",
        "        # Get numeric feature columns\n",
        "        metadata_cols = {\n",
        "            'participant_id', 'timestamp', 'fms', 'fms_label', 'fms_score',\n",
        "            'segment_id', 'dataset', 'folder_name', 'frame'\n",
        "        }\n",
        "        numeric_cols = [col for col in df.columns if col not in metadata_cols\n",
        "                       and df[col].dtype in [np.float64, np.float32, np.int64, np.int32]]\n",
        "\n",
        "        if numeric_cols:\n",
        "            # Prepare data for outlier detection\n",
        "            feature_data = df[numeric_cols].fillna(0).values\n",
        "\n",
        "            # Use Isolation Forest for multivariate outlier detection\n",
        "            outlier_labels = self.outlier_detector.fit_predict(feature_data)\n",
        "            df = df[outlier_labels == 1]  # Keep inliers only\n",
        "\n",
        "        # Remove statistical outliers using IQR method for FMS scores\n",
        "        Q1 = df['fms_score'].quantile(0.25)\n",
        "        Q3 = df['fms_score'].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "        df = df[(df['fms_score'] >= lower_bound) & (df['fms_score'] <= upper_bound)]\n",
        "\n",
        "        print(f\"  Removed {original_len - len(df)} outliers ({(original_len - len(df))/original_len*100:.1f}%)\")\n",
        "        print(f\"  Remaining samples: {len(df)}\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    def create_contextual_features(self, window_data: pd.DataFrame,\n",
        "                                 contextual_features: Dict[str, List[str]]) -> np.ndarray:\n",
        "        \"\"\"Create enhanced features including contextual information\"\"\"\n",
        "\n",
        "        # Standard statistical features\n",
        "        metadata_cols = {\n",
        "            'participant_id', 'timestamp', 'fms', 'fms_label', 'fms_score',\n",
        "            'segment_id', 'dataset', 'folder_name', 'frame'\n",
        "        }\n",
        "\n",
        "        feature_cols = [col for col in window_data.columns if col not in metadata_cols]\n",
        "        numeric_cols = [col for col in feature_cols\n",
        "                       if window_data[col].dtype in [np.float64, np.float32, np.int64, np.int32]]\n",
        "\n",
        "        if not numeric_cols:\n",
        "            return np.array([0.0] * 50)\n",
        "\n",
        "        numeric_data = window_data[numeric_cols].fillna(0).values\n",
        "        numeric_data = np.nan_to_num(numeric_data, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "        features = []\n",
        "\n",
        "        # Basic statistical features\n",
        "        if len(numeric_data) > 0:\n",
        "            features.extend([\n",
        "                np.mean(numeric_data),\n",
        "                np.std(numeric_data),\n",
        "                np.min(numeric_data),\n",
        "                np.max(numeric_data),\n",
        "                np.median(numeric_data),\n",
        "                np.percentile(numeric_data, 25),\n",
        "                np.percentile(numeric_data, 75),\n",
        "                stats.skew(numeric_data.flatten()),\n",
        "                stats.kurtosis(numeric_data.flatten()),\n",
        "                np.ptp(numeric_data)  # Range\n",
        "            ])\n",
        "        else:\n",
        "            features.extend([0.0] * 10)\n",
        "\n",
        "        # Temporal features\n",
        "        if len(numeric_data) > 1:\n",
        "            # Linear trend\n",
        "            time_points = np.arange(len(numeric_data))\n",
        "            slopes = []\n",
        "            for col_idx in range(numeric_data.shape[1]):\n",
        "                try:\n",
        "                    slope = np.polyfit(time_points, numeric_data[:, col_idx], 1)[0]\n",
        "                    slopes.append(slope)\n",
        "                except:\n",
        "                    slopes.append(0.0)\n",
        "\n",
        "            features.extend([\n",
        "                np.mean(slopes),\n",
        "                np.std(slopes),\n",
        "                np.max(slopes),\n",
        "                np.min(slopes)\n",
        "            ])\n",
        "\n",
        "            # Velocity and acceleration\n",
        "            velocity = np.diff(numeric_data, axis=0)\n",
        "            if len(velocity) > 0:\n",
        "                features.extend([\n",
        "                    np.mean(velocity),\n",
        "                    np.std(velocity),\n",
        "                    np.mean(np.abs(velocity))\n",
        "                ])\n",
        "            else:\n",
        "                features.extend([0.0] * 3)\n",
        "\n",
        "            # Acceleration\n",
        "            if len(velocity) > 1:\n",
        "                acceleration = np.diff(velocity, axis=0)\n",
        "                features.extend([\n",
        "                    np.mean(acceleration),\n",
        "                    np.std(acceleration)\n",
        "                ])\n",
        "            else:\n",
        "                features.extend([0.0] * 2)\n",
        "        else:\n",
        "            features.extend([0.0] * 9)\n",
        "\n",
        "        # Contextual features (enhanced for highly correlated features)\n",
        "        contextual_feature_values = []\n",
        "\n",
        "        # Process contextual features with special attention\n",
        "        for feature_type, feature_list in contextual_features.items():\n",
        "            available_features = [f for f in feature_list if f in window_data.columns]\n",
        "\n",
        "            if available_features:\n",
        "                contextual_data = window_data[available_features].fillna(0).values\n",
        "                if len(contextual_data) > 0:\n",
        "                    # Enhanced statistics for contextual features\n",
        "                    contextual_feature_values.extend([\n",
        "                        np.mean(contextual_data),\n",
        "                        np.std(contextual_data),\n",
        "                        np.max(contextual_data) - np.min(contextual_data),  # Range\n",
        "                        np.mean(np.diff(contextual_data, axis=0)) if len(contextual_data) > 1 else 0.0,  # Trend\n",
        "                    ])\n",
        "                else:\n",
        "                    contextual_feature_values.extend([0.0] * 4)\n",
        "            else:\n",
        "                contextual_feature_values.extend([0.0] * 4)\n",
        "\n",
        "        features.extend(contextual_feature_values)\n",
        "\n",
        "        # Frequency domain features (if window is large enough)\n",
        "        if len(numeric_data) > 8:\n",
        "            # Simple frequency features using FFT\n",
        "            try:\n",
        "                fft_features = []\n",
        "                for col_idx in range(min(3, numeric_data.shape[1])):  # Limit to first 3 columns\n",
        "                    fft = np.fft.fft(numeric_data[:, col_idx])\n",
        "                    fft_magnitude = np.abs(fft)\n",
        "                    fft_features.extend([\n",
        "                        np.mean(fft_magnitude[:len(fft_magnitude)//2]),  # Mean of positive frequencies\n",
        "                        np.argmax(fft_magnitude[:len(fft_magnitude)//2])  # Dominant frequency\n",
        "                    ])\n",
        "\n",
        "                features.extend(fft_features)\n",
        "            except:\n",
        "                features.extend([0.0] * 6)\n",
        "        else:\n",
        "            features.extend([0.0] * 6)\n",
        "\n",
        "        return np.array(features, dtype=np.float32)\n",
        "\n",
        "    def create_balanced_sequences(self, sequences: List[Dict]) -> List[Dict]:\n",
        "        \"\"\"Create balanced dataset using oversampling for minority classes\"\"\"\n",
        "\n",
        "        print(\"Balancing dataset...\")\n",
        "\n",
        "        # Convert continuous FMS scores to ordinal classes for balancing\n",
        "        fms_scores = [seq['target_fms'] for seq in sequences]\n",
        "        fms_classes = [int(np.round(score)) - 1 for score in fms_scores]  # 0-9 classes\n",
        "\n",
        "        # Count class distribution\n",
        "        class_counts = Counter(fms_classes)\n",
        "        print(f\"  Original distribution: {dict(sorted(class_counts.items()))}\")\n",
        "\n",
        "        # Find target count (median or mean of class counts)\n",
        "        target_count = int(np.median(list(class_counts.values())))\n",
        "\n",
        "        # Group sequences by class\n",
        "        class_sequences = defaultdict(list)\n",
        "        for seq, cls in zip(sequences, fms_classes):\n",
        "            class_sequences[cls].append(seq)\n",
        "\n",
        "        # Balance by oversampling minority classes\n",
        "        balanced_sequences = []\n",
        "\n",
        "        for cls in range(10):  # FMS classes 1-10 (0-9 indexed)\n",
        "            if cls in class_sequences:\n",
        "                cls_sequences = class_sequences[cls]\n",
        "                current_count = len(cls_sequences)\n",
        "\n",
        "                # Add original sequences\n",
        "                balanced_sequences.extend(cls_sequences)\n",
        "\n",
        "                # Oversample if needed\n",
        "                if current_count < target_count:\n",
        "                    oversample_count = target_count - current_count\n",
        "                    oversampled = np.random.choice(cls_sequences, size=oversample_count, replace=True)\n",
        "                    balanced_sequences.extend(oversampled)\n",
        "\n",
        "        # Shuffle the balanced dataset\n",
        "        np.random.shuffle(balanced_sequences)\n",
        "\n",
        "        # Show new distribution\n",
        "        new_fms_classes = [int(np.round(seq['target_fms'])) - 1 for seq in balanced_sequences]\n",
        "        new_class_counts = Counter(new_fms_classes)\n",
        "        print(f\"  Balanced distribution: {dict(sorted(new_class_counts.items()))}\")\n",
        "        print(f\"  Total sequences: {len(sequences)} -> {len(balanced_sequences)}\")\n",
        "\n",
        "        return balanced_sequences\n",
        "\n",
        "    def process_all_data(self, vrnet_df: pd.DataFrame, vrwalking_df: pd.DataFrame) -> Tuple:\n",
        "        \"\"\"Process all data with enhancements\"\"\"\n",
        "\n",
        "        print(\"Processing data with enhancements...\")\n",
        "\n",
        "        # Remove outliers from each dataset\n",
        "        vrnet_df = self.remove_outliers(vrnet_df)\n",
        "        vrwalking_df = self.remove_outliers(vrwalking_df)\n",
        "\n",
        "        # Combine datasets\n",
        "        combined_df = pd.concat([vrnet_df, vrwalking_df], ignore_index=True)\n",
        "        combined_df = combined_df.dropna(subset=['fms_score'])\n",
        "\n",
        "        # Identify contextual features\n",
        "        contextual_features = self.identify_contextual_features(combined_df)\n",
        "        print(f\"  Identified contextual features: {contextual_features}\")\n",
        "\n",
        "        all_sequences = []\n",
        "\n",
        "        # Process each participant\n",
        "        for participant_id in combined_df['participant_id'].unique():\n",
        "            participant_df = combined_df[combined_df['participant_id'] == participant_id]\n",
        "\n",
        "            if len(participant_df) < self.window_size:\n",
        "                continue\n",
        "\n",
        "            participant_df = participant_df.sort_values('timestamp').reset_index(drop=True)\n",
        "\n",
        "            # Create sequences with overlap\n",
        "            step_size = max(1, int(self.window_size * (1 - self.overlap)))\n",
        "\n",
        "            for i in range(0, len(participant_df) - self.window_size + 1, step_size):\n",
        "                window_data = participant_df.iloc[i:i + self.window_size]\n",
        "                target_fms = window_data['fms_score'].iloc[-1]\n",
        "\n",
        "                if pd.isna(target_fms):\n",
        "                    continue\n",
        "\n",
        "                # Create enhanced features\n",
        "                features = self.create_contextual_features(window_data, contextual_features)\n",
        "\n",
        "                all_sequences.append({\n",
        "                    'features': features,\n",
        "                    'target_fms': float(target_fms),\n",
        "                    'participant_id': participant_id,\n",
        "                    'dataset': participant_df['dataset'].iloc[0]\n",
        "                })\n",
        "\n",
        "        print(f\"Created {len(all_sequences)} sequences\")\n",
        "\n",
        "        # Balance the dataset\n",
        "        balanced_sequences = self.create_balanced_sequences(all_sequences)\n",
        "\n",
        "        # Extract arrays\n",
        "        X = np.array([seq['features'] for seq in balanced_sequences])\n",
        "        y = np.array([seq['target_fms'] for seq in balanced_sequences])\n",
        "        participant_ids = [seq['participant_id'] for seq in balanced_sequences]\n",
        "        datasets = [seq['dataset'] for seq in balanced_sequences]\n",
        "\n",
        "        # Scale features\n",
        "        print(f\"Scaling {X.shape[1]} features...\")\n",
        "        X_scaled = self.scaler.fit_transform(X)\n",
        "\n",
        "        print(f\"Final balanced dataset: {X_scaled.shape[0]} sequences, {X_scaled.shape[1]} features\")\n",
        "        print(f\"FMS range: {y.min():.2f} - {y.max():.2f}\")\n",
        "\n",
        "        return X_scaled, y, participant_ids, datasets\n",
        "\n",
        "class EnhancedOrdinalModel(nn.Module):\n",
        "    \"\"\"Enhanced ordinal regression model with improved architecture\"\"\"\n",
        "\n",
        "    def __init__(self, input_dim: int, hidden_dims: List[int] = [512, 256, 128, 64],\n",
        "                 dropout: float = 0.3, num_ordinal_classes: int = 10):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_ordinal_classes = num_ordinal_classes\n",
        "\n",
        "        # Enhanced feature extraction with residual connections\n",
        "        self.input_norm = nn.BatchNorm1d(input_dim)\n",
        "\n",
        "        # Feature extraction layers with residual connections\n",
        "        layers = []\n",
        "        prev_dim = input_dim\n",
        "\n",
        "        for i, hidden_dim in enumerate(hidden_dims):\n",
        "            # Main path\n",
        "            layers.append(nn.Sequential(\n",
        "                nn.Linear(prev_dim, hidden_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout)\n",
        "            ))\n",
        "\n",
        "            # Add skip connections for larger layers\n",
        "            if prev_dim == hidden_dim:\n",
        "                layers.append(nn.Identity())  # Skip connection\n",
        "\n",
        "            prev_dim = hidden_dim\n",
        "\n",
        "        self.feature_layers = nn.ModuleList(layers)\n",
        "\n",
        "        # Attention mechanism for temporal features\n",
        "        self.attention = nn.MultiheadAttention(\n",
        "            embed_dim=prev_dim,\n",
        "            num_heads=4,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Ordinal regression components\n",
        "        self.ordinal_projection = nn.Linear(prev_dim, 1)\n",
        "        self.ordinal_thresholds = nn.Parameter(torch.linspace(-3, 3, num_ordinal_classes - 1))\n",
        "\n",
        "        # Direct regression head\n",
        "        self.regression_head = nn.Sequential(\n",
        "            nn.Linear(prev_dim, prev_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(prev_dim // 2, 1)\n",
        "        )\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for module in self.modules():\n",
        "            if isinstance(module, nn.Linear):\n",
        "                nn.init.kaiming_normal_(module.weight, mode='fan_in', nonlinearity='relu')\n",
        "                if module.bias is not None:\n",
        "                    nn.init.zeros_(module.bias)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "        # Input normalization\n",
        "        x = self.input_norm(x)\n",
        "\n",
        "        # Feature extraction with residual connections\n",
        "        features = x\n",
        "        for layer in self.feature_layers:\n",
        "            if isinstance(layer, nn.Identity):\n",
        "                continue\n",
        "            new_features = layer(features)\n",
        "\n",
        "            # Add residual connection if dimensions match\n",
        "            if features.shape[-1] == new_features.shape[-1]:\n",
        "                features = features + new_features\n",
        "            else:\n",
        "                features = new_features\n",
        "\n",
        "        # Self-attention for capturing complex relationships\n",
        "        # Reshape for attention (batch_size, seq_len=1, features)\n",
        "        attn_input = features.unsqueeze(1)\n",
        "        attn_output, _ = self.attention(attn_input, attn_input, attn_input)\n",
        "        features = attn_output.squeeze(1) + features  # Residual connection\n",
        "\n",
        "        # Ordinal regression component\n",
        "        ordinal_scores = self.ordinal_projection(features).squeeze(-1)\n",
        "        sorted_thresholds = torch.sort(self.ordinal_thresholds)[0]\n",
        "\n",
        "        # Compute cumulative probabilities\n",
        "        cumulative_probs = torch.sigmoid(\n",
        "            sorted_thresholds.unsqueeze(0) - ordinal_scores.unsqueeze(1)\n",
        "        )\n",
        "\n",
        "        # Convert to class probabilities\n",
        "        padded_probs = torch.cat([\n",
        "            torch.zeros(cumulative_probs.size(0), 1, device=cumulative_probs.device),\n",
        "            cumulative_probs,\n",
        "            torch.ones(cumulative_probs.size(0), 1, device=cumulative_probs.device)\n",
        "        ], dim=1)\n",
        "\n",
        "        class_probs = padded_probs[:, 1:] - padded_probs[:, :-1]\n",
        "\n",
        "        # Expected value (continuous prediction)\n",
        "        class_values = torch.arange(self.num_ordinal_classes, dtype=torch.float32, device=x.device) + 1\n",
        "        expected_values = torch.sum(class_probs * class_values, dim=1)\n",
        "\n",
        "        # Direct regression output\n",
        "        regression_output = self.regression_head(features).squeeze(-1)\n",
        "\n",
        "        return expected_values, regression_output, class_probs\n",
        "\n",
        "    def predict_continuous(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Predict continuous FMS scores\"\"\"\n",
        "        expected_values, regression_output, _ = self.forward(x)\n",
        "\n",
        "        # Weighted combination\n",
        "        combined_output = 0.6 * expected_values + 0.4 * regression_output\n",
        "\n",
        "        # Clamp to valid FMS range\n",
        "        return torch.clamp(combined_output, min=1.0, max=10.0)\n",
        "\n",
        "# Fix the SimplifiedOrdinalLoss class:\n",
        "class SimplifiedOrdinalLoss(nn.Module):\n",
        "    \"\"\"Simplified ordinal loss as backup\"\"\"\n",
        "\n",
        "    def __init__(self, ordinal_weight: float = 0.7, regression_weight: float = 0.3):\n",
        "        super().__init__()\n",
        "        self.ordinal_weight = ordinal_weight\n",
        "        self.regression_weight = regression_weight\n",
        "\n",
        "    def ordinal_loss(self, class_probs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Simple ordinal loss using cross entropy\"\"\"\n",
        "        batch_size = class_probs.size(0)\n",
        "        num_classes = class_probs.size(1)\n",
        "\n",
        "        # Ensure targets are in valid range [1, 10] then convert to [0, 9]\n",
        "        targets_clamped = torch.clamp(targets, min=1.0, max=10.0)\n",
        "        target_classes = torch.clamp(torch.round(targets_clamped) - 1, 0, num_classes - 1).long()\n",
        "\n",
        "        # Ensure class_probs are valid probabilities\n",
        "        class_probs_safe = torch.clamp(class_probs, min=1e-7, max=1.0)\n",
        "        class_probs_safe = class_probs_safe / class_probs_safe.sum(dim=1, keepdim=True)\n",
        "\n",
        "        # Cross entropy loss\n",
        "        return F.cross_entropy(torch.log(class_probs_safe + 1e-7), target_classes)\n",
        "\n",
        "    def forward(self, expected_values: torch.Tensor, regression_output: torch.Tensor,\n",
        "                class_probs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        # Clamp all inputs to safe ranges\n",
        "        expected_values = torch.clamp(expected_values, min=1.0, max=10.0)\n",
        "        regression_output = torch.clamp(regression_output, min=1.0, max=10.0)\n",
        "        targets = torch.clamp(targets, min=1.0, max=10.0)\n",
        "\n",
        "        # Ordinal loss\n",
        "        ord_loss = self.ordinal_loss(class_probs, targets)\n",
        "\n",
        "        # Regression loss\n",
        "        reg_loss = F.smooth_l1_loss(regression_output, targets)\n",
        "\n",
        "        # Combined prediction loss\n",
        "        combined_pred = 0.7 * expected_values + 0.3 * regression_output\n",
        "        combined_pred = torch.clamp(combined_pred, min=1.0, max=10.0)\n",
        "        combined_loss = F.smooth_l1_loss(combined_pred, targets)\n",
        "\n",
        "        # Total loss\n",
        "        total_loss = (self.ordinal_weight * ord_loss +\n",
        "                     self.regression_weight * reg_loss +\n",
        "                     0.2 * combined_loss)\n",
        "\n",
        "        return gtotal_loss\n",
        "\n",
        "def compute_enhanced_metrics(y_true: np.ndarray, y_pred: np.ndarray) -> Dict[str, float]:\n",
        "    \"\"\"Compute only the requested metrics\"\"\"\n",
        "\n",
        "    # Basic metrics\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    # Accuracy metrics\n",
        "    errors = np.abs(y_true - y_pred)\n",
        "    acc_0_5 = np.mean(errors <= 0.5)\n",
        "    acc_1_0 = np.mean(errors <= 1.0)\n",
        "    acc_1_5 = np.mean(errors <= 1.5)\n",
        "\n",
        "    return {\n",
        "        'MSE': mse,\n",
        "        'RMSE': rmse,\n",
        "        'Acc@0.5': acc_0_5,\n",
        "        'Acc@1.0': acc_1_0,\n",
        "        'Acc@1.5': acc_1_5\n",
        "    }\n",
        "\n",
        "class HyperparameterTuner:\n",
        "    \"\"\"Hyperparameter tuning using Optuna\"\"\"\n",
        "\n",
        "    def __init__(self, X: np.ndarray, y: np.ndarray, participant_ids: List[str],\n",
        "                 datasets: List[str], n_folds: int = 5):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.participant_ids = participant_ids\n",
        "        self.datasets = datasets\n",
        "        self.n_folds = n_folds\n",
        "\n",
        "    def objective(self, trial):\n",
        "        # Suggest hyperparameters\n",
        "        params = {\n",
        "            'hidden_dims': [\n",
        "                trial.suggest_int('hidden_dim_1', 256, 1024, step=128),\n",
        "                trial.suggest_int('hidden_dim_2', 128, 512, step=64),\n",
        "                trial.suggest_int('hidden_dim_3', 64, 256, step=32),\n",
        "                trial.suggest_int('hidden_dim_4', 32, 128, step=16)\n",
        "            ],\n",
        "            'dropout': trial.suggest_float('dropout', 0.1, 0.5),\n",
        "            'lr': trial.suggest_float('lr', 1e-4, 1e-2, log=True),\n",
        "            'batch_size': trial.suggest_categorical('batch_size', [32, 64, 128]),\n",
        "            'ordinal_weight': trial.suggest_float('ordinal_weight', 0.4, 0.8),\n",
        "            'regression_weight': trial.suggest_float('regression_weight', 0.2, 0.6)\n",
        "        }\n",
        "\n",
        "        # Cross-validation\n",
        "        unique_participants = list(set(self.participant_ids))\n",
        "        participant_to_group = {pid: i for i, pid in enumerate(unique_participants)}\n",
        "        groups = [participant_to_group[pid] for pid in self.participant_ids]\n",
        "\n",
        "        kfold = GroupKFold(n_splits=self.n_folds)\n",
        "        splits = list(kfold.split(self.X, self.y, groups))\n",
        "\n",
        "        fold_rmses = []\n",
        "\n",
        "        for fold_idx, (train_idx, val_idx) in enumerate(splits[:3]):  # Use only 3 folds for speed\n",
        "            X_train, X_val = self.X[train_idx], self.X[val_idx]\n",
        "            y_train, y_val = self.y[train_idx], self.y[val_idx]\n",
        "\n",
        "            # Quick training (reduced epochs for tuning)\n",
        "            rmse = self._train_fold(X_train, y_train, X_val, y_val, params, max_epochs=30)\n",
        "            fold_rmses.append(rmse)\n",
        "\n",
        "            # Pruning\n",
        "            trial.report(np.mean(fold_rmses), fold_idx)\n",
        "            if trial.should_prune():\n",
        "                raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "        return np.mean(fold_rmses)\n",
        "\n",
        "    def _train_fold(self, X_train, y_train, X_val, y_val, params, max_epochs=30):\n",
        "        \"\"\"Quick training for hyperparameter tuning\"\"\"\n",
        "\n",
        "        device = torch.device('cpu')\n",
        "\n",
        "        # Create model\n",
        "        model = EnhancedOrdinalModel(\n",
        "            input_dim=X_train.shape[1],\n",
        "            hidden_dims=params['hidden_dims'],\n",
        "            dropout=params['dropout']\n",
        "        ).to(device)\n",
        "\n",
        "        # Loss and optimizer\n",
        "        criterion = SimplifiedOrdinalLoss(\n",
        "            ordinal_weight=params['ordinal_weight'],\n",
        "            regression_weight=params['regression_weight']\n",
        "        )\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=params['lr'])\n",
        "\n",
        "        # Data loaders\n",
        "        train_dataset = EnhancedVRDataset(X_train, y_train, ['dummy'] * len(X_train), ['dummy'] * len(X_train))\n",
        "        val_dataset = EnhancedVRDataset(X_val, y_val, ['dummy'] * len(X_val), ['dummy'] * len(X_val))\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=params['batch_size'], shuffle=True)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=params['batch_size'], shuffle=False)\n",
        "\n",
        "        best_rmse = float('inf')\n",
        "\n",
        "        for epoch in range(max_epochs):\n",
        "            # Training\n",
        "            model.train()\n",
        "            for batch in train_loader:\n",
        "                features = batch['features'].to(device)\n",
        "                targets = batch['target'].to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                expected_values, regression_output, class_probs = model(features)\n",
        "                loss = criterion(expected_values, regression_output, class_probs, targets)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            # Validation\n",
        "            model.eval()\n",
        "            val_predictions = []\n",
        "            val_targets = []\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for batch in val_loader:\n",
        "                    features = batch['features'].to(device)\n",
        "                    targets = batch['target'].to(device)\n",
        "\n",
        "                    predictions = model.predict_continuous(features)\n",
        "\n",
        "                    val_predictions.extend(predictions.cpu().numpy())\n",
        "                    val_targets.extend(targets.cpu().numpy())\n",
        "\n",
        "            rmse = np.sqrt(mean_squared_error(val_targets, val_predictions))\n",
        "            best_rmse = min(best_rmse, rmse)\n",
        "\n",
        "        return best_rmse\n",
        "\n",
        "    def tune(self, n_trials: int = 50):\n",
        "        \"\"\"Run hyperparameter tuning\"\"\"\n",
        "\n",
        "        study = optuna.create_study(direction='minimize')\n",
        "        study.optimize(self.objective, n_trials=n_trials)\n",
        "\n",
        "        print(\"Best hyperparameters:\")\n",
        "        for key, value in study.best_params.items():\n",
        "            print(f\"  {key}: {value}\")\n",
        "\n",
        "        print(f\"Best RMSE: {study.best_value:.4f}\")\n",
        "\n",
        "        return study.best_params\n",
        "\n",
        "class EnhancedVRDataset(Dataset):\n",
        "    \"\"\"Enhanced dataset with weighted sampling for class balance\"\"\"\n",
        "\n",
        "    def __init__(self, features: np.ndarray, targets: np.ndarray,\n",
        "                 participant_ids: List[str], datasets: List[str]):\n",
        "        self.features = torch.FloatTensor(features)\n",
        "        self.targets = torch.FloatTensor(targets)\n",
        "        self.participant_ids = participant_ids\n",
        "        self.datasets = datasets\n",
        "\n",
        "        # Create participant groups for CV\n",
        "        self.unique_participants = list(set(participant_ids))\n",
        "        self.participant_to_group = {pid: i for i, pid in enumerate(self.unique_participants)}\n",
        "        self.groups = [self.participant_to_group[pid] for pid in participant_ids]\n",
        "\n",
        "        # Calculate sample weights for balanced training\n",
        "        self.sample_weights = self._calculate_sample_weights()\n",
        "\n",
        "    def _calculate_sample_weights(self) -> torch.Tensor:\n",
        "        \"\"\"Calculate sample weights for balanced training\"\"\"\n",
        "        # Convert continuous targets to ordinal classes\n",
        "        target_classes = torch.round(self.targets).long() - 1  # 0-9 classes\n",
        "        target_classes = torch.clamp(target_classes, 0, 9)  # Ensure valid range\n",
        "\n",
        "        # Calculate class weights\n",
        "        class_counts = torch.bincount(target_classes, minlength=10)\n",
        "        total_samples = len(target_classes)\n",
        "\n",
        "        # Inverse frequency weighting (add small epsilon to avoid division by zero)\n",
        "        class_weights = total_samples / (len(class_counts) * (class_counts.float() + 1e-6))\n",
        "\n",
        "        # Assign weights to each sample\n",
        "        sample_weights = class_weights[target_classes]\n",
        "\n",
        "        return sample_weights\n",
        "\n",
        "    def get_weighted_sampler(self) -> WeightedRandomSampler:\n",
        "        \"\"\"Get weighted sampler for balanced training\"\"\"\n",
        "        return WeightedRandomSampler(\n",
        "            weights=self.sample_weights,\n",
        "            num_samples=len(self.sample_weights),\n",
        "            replacement=True\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'features': self.features[idx],\n",
        "            'target': self.targets[idx],\n",
        "            'participant_id': self.participant_ids[idx],\n",
        "            'dataset': self.datasets[idx]\n",
        "        }\n",
        "\n",
        "def train_enhanced_model(train_loader: DataLoader, val_loader: DataLoader,\n",
        "                        input_dim: int, hyperparams: Dict, num_epochs: int = 100,\n",
        "                        fold_idx: int = 0) -> Dict:\n",
        "    \"\"\"Train enhanced ordinal regression model\"\"\"\n",
        "\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "    # Initialize model with hyperparameters\n",
        "    model = EnhancedOrdinalModel(\n",
        "        input_dim=input_dim,\n",
        "        hidden_dims=hyperparams.get('hidden_dims', [512, 256, 128, 64]),\n",
        "        dropout=hyperparams.get('dropout', 0.3)\n",
        "    ).to(device)\n",
        "\n",
        "    # Use simplified loss function for stability\n",
        "    try:\n",
        "        criterion = SimplifiedOrdinalLoss(\n",
        "            ordinal_weight=hyperparams.get('ordinal_weight', 0.6),\n",
        "            regression_weight=hyperparams.get('regression_weight', 0.4)\n",
        "        )\n",
        "        print(f\"  Using FocalOrdinalLoss\")\n",
        "    except:\n",
        "        criterion = SimplifiedOrdinalLoss(\n",
        "            ordinal_weight=hyperparams.get('ordinal_weight', 0.7),\n",
        "            regression_weight=hyperparams.get('regression_weight', 0.3)\n",
        "        )\n",
        "        print(f\"  Using SimplifiedOrdinalLoss (fallback)\")\n",
        "\n",
        "    # Optimizer with weight decay\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=hyperparams.get('lr', 1e-3),\n",
        "        weight_decay=hyperparams.get('weight_decay', 1e-4)\n",
        "    )\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "        optimizer,\n",
        "        max_lr=hyperparams.get('lr', 1e-3) * 2,\n",
        "        epochs=num_epochs,\n",
        "        steps_per_epoch=len(train_loader),\n",
        "        pct_start=0.3\n",
        "    )\n",
        "\n",
        "    best_val_rmse = float('inf')\n",
        "    patience = 30\n",
        "    patience_counter = 0\n",
        "\n",
        "    print(f\"\\nTraining Enhanced Fold {fold_idx + 1}...\")\n",
        "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "    # Training history\n",
        "    train_losses = []\n",
        "    val_rmses = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "\n",
        "        try:\n",
        "            for batch in train_loader:\n",
        "                features = batch['features'].to(device)\n",
        "                targets = batch['target'].to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                expected_values, regression_output, class_probs = model(features)\n",
        "                loss = criterion(expected_values, regression_output, class_probs, targets)\n",
        "\n",
        "                # Check for NaN loss\n",
        "                if torch.isnan(loss):\n",
        "                    print(f\"    Warning: NaN loss detected at epoch {epoch+1}\")\n",
        "                    continue\n",
        "\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "\n",
        "                train_loss += loss.item()\n",
        "        except Exception as e:\n",
        "            print(f\"    Training error at epoch {epoch+1}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_predictions = []\n",
        "        val_targets = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                features = batch['features'].to(device)\n",
        "                targets = batch['target'].to(device)\n",
        "\n",
        "                try:\n",
        "                    predictions = model.predict_continuous(features)\n",
        "                    val_predictions.extend(predictions.cpu().numpy())\n",
        "                    val_targets.extend(targets.cpu().numpy())\n",
        "                except Exception as e:\n",
        "                    print(f\"    Validation error: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "        if not val_predictions:\n",
        "            print(f\"    No valid predictions at epoch {epoch+1}\")\n",
        "            continue\n",
        "\n",
        "        # Calculate metrics\n",
        "        val_metrics = compute_enhanced_metrics(np.array(val_targets), np.array(val_predictions))\n",
        "        val_rmse = val_metrics['RMSE']\n",
        "\n",
        "        train_losses.append(train_loss / len(train_loader) if len(train_loader) > 0 else 0)\n",
        "        val_rmses.append(val_rmse)\n",
        "\n",
        "        # Print progress\n",
        "        if epoch % 20 == 0 or epoch == num_epochs - 1:\n",
        "            print(f'  Epoch {epoch+1:3d}: Loss: {train_loss/max(len(train_loader), 1):.4f}, '\n",
        "                  f'RMSE: {val_rmse:.4f}, Acc@1.0: {val_metrics[\"Acc@1.0\"]:.4f}')\n",
        "\n",
        "        # Early stopping\n",
        "        if val_rmse < best_val_rmse:\n",
        "            best_val_rmse = val_rmse\n",
        "            patience_counter = 0\n",
        "            torch.save(model.state_dict(), f'best_enhanced_model_fold_{fold_idx}.pth')\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(f'    Early stopping at epoch {epoch+1}')\n",
        "                break\n",
        "\n",
        "    # Load best model and get final predictions\n",
        "    try:\n",
        "        model.load_state_dict(torch.load(f'best_enhanced_model_fold_{fold_idx}.pth'))\n",
        "    except:\n",
        "        print(f\"    Warning: Could not load best model, using current state\")\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    final_predictions = []\n",
        "    final_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            features = batch['features'].to(device)\n",
        "            targets = batch['target'].to(device)\n",
        "\n",
        "            try:\n",
        "                predictions = model.predict_continuous(features)\n",
        "                final_predictions.extend(predictions.cpu().numpy())\n",
        "                final_targets.extend(targets.cpu().numpy())\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "    if final_predictions:\n",
        "        final_metrics = compute_enhanced_metrics(np.array(final_targets), np.array(final_predictions))\n",
        "\n",
        "        print(f'  Final Fold {fold_idx + 1} Results:')\n",
        "        for metric, value in final_metrics.items():\n",
        "            print(f'    {metric}: {value:.4f}')\n",
        "    else:\n",
        "        print(f'  Warning: No valid final predictions for fold {fold_idx + 1}')\n",
        "        final_metrics = {'RMSE': 999.0, 'MSE': 999.0, 'Acc@0.5': 0.0, 'Acc@1.0': 0.0, 'Acc@1.5': 0.0}\n",
        "        final_predictions = [5.0] * len(val_loader.dataset)  # Dummy predictions\n",
        "        final_targets = [5.0] * len(val_loader.dataset)      # Dummy targets\n",
        "\n",
        "    return {\n",
        "        'predictions': final_predictions,\n",
        "        'targets': final_targets,\n",
        "        'metrics': final_metrics,\n",
        "        'train_losses': train_losses,\n",
        "        'val_rmses': val_rmses\n",
        "    }\n",
        "\n",
        "def create_enhanced_visualizations(fold_results: List[Dict], cv_metrics: Dict):\n",
        "    \"\"\"Create comprehensive visualizations\"\"\"\n",
        "\n",
        "    # Combine all results\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "    all_train_losses = []\n",
        "    all_val_rmses = []\n",
        "\n",
        "    for fold_result in fold_results:\n",
        "        all_predictions.extend(fold_result['predictions'])\n",
        "        all_targets.extend(fold_result['targets'])\n",
        "        all_train_losses.extend(fold_result['train_losses'])\n",
        "        all_val_rmses.extend(fold_result['val_rmses'])\n",
        "\n",
        "    all_predictions = np.array(all_predictions)\n",
        "    all_targets = np.array(all_targets)\n",
        "\n",
        "    # Create comprehensive plots\n",
        "    fig = plt.figure(figsize=(20, 16))\n",
        "\n",
        "    # 1. Predictions vs True Values\n",
        "    ax1 = plt.subplot(3, 3, 1)\n",
        "    plt.scatter(all_targets, all_predictions, alpha=0.6, s=15, c='steelblue')\n",
        "    plt.plot([all_targets.min(), all_targets.max()],\n",
        "             [all_targets.min(), all_targets.max()], 'r--', lw=2)\n",
        "    plt.xlabel('True FMS Scores')\n",
        "    plt.ylabel('Predicted FMS Scores')\n",
        "    plt.title(f'Predictions vs True Values\\nRMSE = {cv_metrics[\"RMSE_mean\"]:.3f}')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # Add R² annotation\n",
        "    from scipy.stats import pearsonr\n",
        "    r, _ = pearsonr(all_targets, all_predictions)\n",
        "    plt.text(0.05, 0.95, f'R² = {r**2:.3f}', transform=ax1.transAxes,\n",
        "             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "    # 2. Residuals Plot\n",
        "    ax2 = plt.subplot(3, 3, 2)\n",
        "    residuals = all_predictions - all_targets\n",
        "    plt.scatter(all_targets, residuals, alpha=0.6, s=15, c='lightcoral')\n",
        "    plt.axhline(y=0, color='r', linestyle='--', lw=2)\n",
        "    plt.xlabel('True FMS Scores')\n",
        "    plt.ylabel('Residuals')\n",
        "    plt.title('Residual Plot')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # 3. Distribution of Residuals\n",
        "    ax3 = plt.subplot(3, 3, 3)\n",
        "    plt.hist(residuals, bins=30, alpha=0.7, edgecolor='black', color='lightgreen')\n",
        "    plt.axvline(x=0, color='r', linestyle='--', lw=2)\n",
        "    plt.xlabel('Residuals')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title(f'Residual Distribution\\nMean = {np.mean(residuals):.3f}')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # 4. Q-Q Plot for Residuals\n",
        "    ax4 = plt.subplot(3, 3, 4)\n",
        "    from scipy import stats\n",
        "    stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
        "    plt.title('Q-Q Plot of Residuals')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # 5. Performance by Fold\n",
        "    ax5 = plt.subplot(3, 3, 5)\n",
        "    metrics_to_plot = ['RMSE', 'MSE', 'Acc@0.5', 'Acc@1.0', 'Acc@1.5']\n",
        "    fold_metrics = {metric: [fold['metrics'][metric] for fold in fold_results]\n",
        "                   for metric in metrics_to_plot}\n",
        "\n",
        "    x_pos = np.arange(len(fold_results))\n",
        "    width = 0.15\n",
        "\n",
        "    for i, metric in enumerate(metrics_to_plot):\n",
        "        plt.bar(x_pos + i*width, fold_metrics[metric], width,\n",
        "                label=metric, alpha=0.8)\n",
        "\n",
        "    plt.xlabel('Fold')\n",
        "    plt.ylabel('Metric Value')\n",
        "    plt.title('Performance by Fold')\n",
        "    plt.xticks(x_pos + width * 2, [f'F{i+1}' for i in range(len(fold_results))])\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # 6. Error Distribution by FMS Range\n",
        "    ax6 = plt.subplot(3, 3, 6)\n",
        "    fms_ranges = [(1, 3), (3, 5), (5, 7), (7, 10)]\n",
        "    range_errors = []\n",
        "    range_labels = []\n",
        "\n",
        "    for low, high in fms_ranges:\n",
        "        mask = (all_targets >= low) & (all_targets < high)\n",
        "        if np.any(mask):\n",
        "            range_residuals = np.abs(residuals[mask])\n",
        "            range_errors.append(range_residuals)\n",
        "            range_labels.append(f'{low}-{high}')\n",
        "\n",
        "    if range_errors:\n",
        "        plt.boxplot(range_errors, labels=range_labels)\n",
        "        plt.xlabel('FMS Score Range')\n",
        "        plt.ylabel('Absolute Error')\n",
        "        plt.title('Error Distribution by FMS Range')\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # 7. Training Progress (Average across folds)\n",
        "    ax7 = plt.subplot(3, 3, 7)\n",
        "    if all_train_losses:\n",
        "        # Truncate to common length\n",
        "        min_length = min(len(fold_result['train_losses']) for fold_result in fold_results)\n",
        "        train_losses_aligned = [fold_result['train_losses'][:min_length] for fold_result in fold_results]\n",
        "        val_rmses_aligned = [fold_result['val_rmses'][:min_length] for fold_result in fold_results]\n",
        "\n",
        "        avg_train_loss = np.mean(train_losses_aligned, axis=0)\n",
        "        avg_val_rmse = np.mean(val_rmses_aligned, axis=0)\n",
        "\n",
        "        epochs = range(1, len(avg_train_loss) + 1)\n",
        "\n",
        "        ax7_twin = ax7.twinx()\n",
        "        line1 = ax7.plot(epochs, avg_train_loss, 'b-', label='Training Loss')\n",
        "        line2 = ax7_twin.plot(epochs, avg_val_rmse, 'r-', label='Validation RMSE')\n",
        "\n",
        "        ax7.set_xlabel('Epoch')\n",
        "        ax7.set_ylabel('Training Loss', color='b')\n",
        "        ax7_twin.set_ylabel('Validation RMSE', color='r')\n",
        "        ax7.set_title('Training Progress')\n",
        "\n",
        "        # Combined legend\n",
        "        lines = line1 + line2\n",
        "        labels = [l.get_label() for l in lines]\n",
        "        ax7.legend(lines, labels, loc='upper right')\n",
        "\n",
        "        ax7.grid(True, alpha=0.3)\n",
        "\n",
        "    # 8. Accuracy Metrics Comparison\n",
        "    ax8 = plt.subplot(3, 3, 8)\n",
        "    accuracy_metrics = ['Acc@0.5', 'Acc@1.0', 'Acc@1.5']\n",
        "    accuracy_values = [cv_metrics[f'{metric}_mean'] for metric in accuracy_metrics]\n",
        "    accuracy_stds = [cv_metrics[f'{metric}_std'] for metric in accuracy_metrics]\n",
        "\n",
        "    bars = plt.bar(accuracy_metrics, accuracy_values, yerr=accuracy_stds,\n",
        "                   capsize=5, alpha=0.8, color=['skyblue', 'lightgreen', 'salmon'])\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Accuracy at Different Tolerances')\n",
        "    plt.ylim(0, 1)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for bar, val, std in zip(bars, accuracy_values, accuracy_stds):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                f'{val:.3f}±{std:.3f}', ha='center', va='bottom')\n",
        "\n",
        "    # 9. Class-wise Performance\n",
        "    ax9 = plt.subplot(3, 3, 9)\n",
        "\n",
        "    # Bin predictions and targets by FMS classes\n",
        "    fms_classes = np.arange(1, 11)\n",
        "    class_rmses = []\n",
        "\n",
        "    for cls in fms_classes:\n",
        "        mask = (np.round(all_targets) == cls)\n",
        "        if np.any(mask):\n",
        "            class_predictions = all_predictions[mask]\n",
        "            class_targets = all_targets[mask]\n",
        "            class_rmse = np.sqrt(mean_squared_error(class_targets, class_predictions))\n",
        "            class_rmses.append(class_rmse)\n",
        "        else:\n",
        "            class_rmses.append(0)\n",
        "\n",
        "    plt.bar(fms_classes, class_rmses, alpha=0.8, color='mediumpurple')\n",
        "    plt.xlabel('FMS Class')\n",
        "    plt.ylabel('RMSE')\n",
        "    plt.title('Performance by FMS Class')\n",
        "    plt.xticks(fms_classes)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print detailed analysis\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ENHANCED MODEL PERFORMANCE ANALYSIS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    print(f\"Overall Performance:\")\n",
        "    print(f\"  RMSE: {cv_metrics['RMSE_mean']:.4f} ± {cv_metrics['RMSE_std']:.4f}\")\n",
        "    print(f\"  MSE:  {cv_metrics['MSE_mean']:.4f} ± {cv_metrics['MSE_std']:.4f}\")\n",
        "    print(f\"  Acc@0.5: {cv_metrics['Acc@0.5_mean']:.4f} ± {cv_metrics['Acc@0.5_std']:.4f}\")\n",
        "    print(f\"  Acc@1.0: {cv_metrics['Acc@1.0_mean']:.4f} ± {cv_metrics['Acc@1.0_std']:.4f}\")\n",
        "    print(f\"  Acc@1.5: {cv_metrics['Acc@1.5_mean']:.4f} ± {cv_metrics['Acc@1.5_std']:.4f}\")\n",
        "\n",
        "    # Performance interpretation\n",
        "    rmse_mean = cv_metrics['RMSE_mean']\n",
        "    acc_1_0 = cv_metrics['Acc@1.0_mean']\n",
        "\n",
        "    print(f\"\\nPerformance Interpretation:\")\n",
        "    if rmse_mean < 1.0:\n",
        "        print(\"  ✅ Excellent performance - RMSE < 1.0 FMS point\")\n",
        "    elif rmse_mean < 1.5:\n",
        "        print(\"  ✅ Good performance - RMSE < 1.5 FMS points\")\n",
        "    elif rmse_mean < 2.0:\n",
        "        print(\"  ⚠️  Moderate performance - RMSE < 2.0 FMS points\")\n",
        "    else:\n",
        "        print(\"  ❌ Poor performance - RMSE > 2.0 FMS points\")\n",
        "\n",
        "    if acc_1_0 > 0.8:\n",
        "        print(\"  ✅ High accuracy - >80% predictions within 1.0 FMS point\")\n",
        "    elif acc_1_0 > 0.6:\n",
        "        print(\"  ✅ Good accuracy - >60% predictions within 1.0 FMS point\")\n",
        "    else:\n",
        "        print(\"  ⚠️  Low accuracy - <60% predictions within 1.0 FMS point\")\n",
        "\n",
        "def run_enhanced_pipeline(vrnet_csv_path: str, vrwalking_csv_path: str,\n",
        "                         window_size: int = 60, n_folds: int = 10,\n",
        "                         num_epochs: int = 100, tune_hyperparams: bool = True):\n",
        "    \"\"\"Run the complete enhanced pipeline\"\"\"\n",
        "\n",
        "    print(\"🚀 STARTING ENHANCED ORDINAL REGRESSION PIPELINE\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    try:\n",
        "        # Load and clean data (reuse existing function)\n",
        "        print(\"Loading and cleaning data...\")\n",
        "        vrnet_df, vrwalking_df = load_and_clean_data(vrnet_csv_path, vrwalking_csv_path)\n",
        "\n",
        "        # Process with enhanced processor\n",
        "        processor = EnhancedTimeSeriesProcessor(window_size=window_size, overlap=0.5)\n",
        "        X, y, participant_ids, datasets = processor.process_all_data(vrnet_df, vrwalking_df)\n",
        "\n",
        "        # Hyperparameter tuning\n",
        "        best_params = {}\n",
        "        if tune_hyperparams:\n",
        "            print(\"\\n🎯 HYPERPARAMETER TUNING\")\n",
        "            print(\"-\" * 40)\n",
        "\n",
        "            tuner = HyperparameterTuner(X, y, participant_ids, datasets, n_folds=3)\n",
        "            best_params = tuner.tune(n_trials=30)\n",
        "        else:\n",
        "            # Default hyperparameters\n",
        "            best_params = {\n",
        "                'hidden_dims': [512, 256, 128, 64],\n",
        "                'dropout': 0.3,\n",
        "                'lr': 1e-3,\n",
        "                'batch_size': 64,\n",
        "                'ordinal_weight': 0.6,\n",
        "                'regression_weight': 0.4,\n",
        "                'weight_decay': 1e-4\n",
        "            }\n",
        "\n",
        "        # Cross-validation with enhanced model\n",
        "        print(f\"\\n📊 CROSS-VALIDATION ({n_folds} folds)\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        unique_participants = list(set(participant_ids))\n",
        "        participant_to_group = {pid: i for i, pid in enumerate(unique_participants)}\n",
        "        groups = [participant_to_group[pid] for pid in participant_ids]\n",
        "\n",
        "        kfold = GroupKFold(n_splits=n_folds)\n",
        "        splits = list(kfold.split(X, y, groups))\n",
        "\n",
        "        fold_results = []\n",
        "\n",
        "        for fold_idx, (train_indices, val_indices) in enumerate(splits):\n",
        "            print(f\"\\n--- FOLD {fold_idx + 1}/{n_folds} ---\")\n",
        "\n",
        "            # Split data\n",
        "            X_train, X_val = X[train_indices], X[val_indices]\n",
        "            y_train, y_val = y[train_indices], y[val_indices]\n",
        "            train_pids = [participant_ids[i] for i in train_indices]\n",
        "            val_pids = [participant_ids[i] for i in val_indices]\n",
        "            train_datasets = [datasets[i] for i in train_indices]\n",
        "            val_datasets = [datasets[i] for i in val_indices]\n",
        "\n",
        "            # Verify no leakage\n",
        "            assert len(set(train_pids) & set(val_pids)) == 0, f\"Participant leakage in fold {fold_idx}!\"\n",
        "\n",
        "            print(f\"Train: {len(X_train)} sequences, {len(set(train_pids))} participants\")\n",
        "            print(f\"Val: {len(X_val)} sequences, {len(set(val_pids))} participants\")\n",
        "\n",
        "            # Create enhanced datasets\n",
        "            train_dataset = EnhancedVRDataset(X_train, y_train, train_pids, train_datasets)\n",
        "            val_dataset = EnhancedVRDataset(X_val, y_val, val_pids, val_datasets)\n",
        "\n",
        "            # Use weighted sampler for balanced training\n",
        "            train_sampler = train_dataset.get_weighted_sampler()\n",
        "            train_loader = DataLoader(\n",
        "                train_dataset,\n",
        "                batch_size=best_params.get('batch_size', 64),\n",
        "                sampler=train_sampler,\n",
        "                num_workers=0\n",
        "            )\n",
        "            val_loader = DataLoader(\n",
        "                val_dataset,\n",
        "                batch_size=best_params.get('batch_size', 64),\n",
        "                shuffle=False,\n",
        "                num_workers=0\n",
        "            )\n",
        "\n",
        "            # Train enhanced model\n",
        "            fold_result = train_enhanced_model(\n",
        "                train_loader=train_loader,\n",
        "                val_loader=val_loader,\n",
        "                input_dim=X.shape[1],\n",
        "                hyperparams=best_params,\n",
        "                num_epochs=num_epochs,\n",
        "                fold_idx=fold_idx\n",
        "            )\n",
        "\n",
        "            fold_results.append(fold_result)\n",
        "\n",
        "        # Aggregate results\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"FINAL RESULTS\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        # Calculate CV metrics\n",
        "        metric_names = ['RMSE', 'MSE', 'Acc@0.5', 'Acc@1.0', 'Acc@1.5']\n",
        "        cv_metrics = {}\n",
        "\n",
        "        for metric in metric_names:\n",
        "            values = [fold['metrics'][metric] for fold in fold_results]\n",
        "            cv_metrics[f\"{metric}_mean\"] = np.mean(values)\n",
        "            cv_metrics[f\"{metric}_std\"] = np.std(values)\n",
        "\n",
        "        # Print results\n",
        "        print(f\"Cross-Validation Results ({n_folds} folds):\")\n",
        "        for metric in metric_names:\n",
        "            mean_val = cv_metrics[f\"{metric}_mean\"]\n",
        "            std_val = cv_metrics[f\"{metric}_std\"]\n",
        "            print(f\"  {metric:>8s}: {mean_val:.4f} ± {std_val:.4f}\")\n",
        "\n",
        "        # Create visualizations\n",
        "        print(\"\\n📈 GENERATING VISUALIZATIONS...\")\n",
        "        create_enhanced_visualizations(fold_results, cv_metrics)\n",
        "\n",
        "        return {\n",
        "            'cv_metrics': cv_metrics,\n",
        "            'fold_results': fold_results,\n",
        "            'best_hyperparams': best_params,\n",
        "            'processor': processor\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Pipeline failed: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "# Additional utility function for feature importance analysis\n",
        "def analyze_feature_importance(model, X_sample, feature_names=None):\n",
        "    \"\"\"Analyze feature importance using gradient-based methods\"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    # Convert to tensor\n",
        "    X_tensor = torch.FloatTensor(X_sample).to(device)\n",
        "    X_tensor.requires_grad_()\n",
        "\n",
        "    # Forward pass\n",
        "    output = model.predict_continuous(X_tensor)\n",
        "\n",
        "    # Compute gradients\n",
        "    gradients = torch.autograd.grad(\n",
        "        outputs=output.sum(),\n",
        "        inputs=X_tensor,\n",
        "        create_graph=False,\n",
        "        retain_graph=False\n",
        "    )[0]\n",
        "\n",
        "    # Feature importance scores\n",
        "    importance_scores = torch.abs(gradients).mean(dim=0).cpu().numpy()\n",
        "\n",
        "    # Create feature names if not provided\n",
        "    if feature_names is None:\n",
        "        feature_names = [f'Feature_{i}' for i in range(len(importance_scores))]\n",
        "\n",
        "    # Sort by importance\n",
        "    sorted_indices = np.argsort(importance_scores)[::-1]\n",
        "\n",
        "    return {\n",
        "        'importance_scores': importance_scores,\n",
        "        'sorted_indices': sorted_indices,\n",
        "        'feature_names': feature_names\n",
        "    }\n",
        "\n",
        "# Example usage and main execution\n",
        "def main():\n",
        "    \"\"\"Main execution function\"\"\"\n",
        "\n",
        "    # File paths\n",
        "    vrnet_csv_path = \"/content/drive/MyDrive/[anon]/vrnet_preprocessed_1hz_complete.csv\"\n",
        "    vrwalking_csv_path = \"/content/drive/MyDrive/[anon]/final_data.csv\"\n",
        "\n",
        "    # Run enhanced pipeline\n",
        "    results = run_enhanced_pipeline(\n",
        "        vrnet_csv_path=vrnet_csv_path,\n",
        "        vrwalking_csv_path=vrwalking_csv_path,\n",
        "        window_size=60,\n",
        "        n_folds=10,\n",
        "        num_epochs=100,\n",
        "        tune_hyperparams=True  # Set to False to skip hyperparameter tuning\n",
        "    )\n",
        "\n",
        "    if results is not None:\n",
        "        print(\"\\n🎉 ENHANCED PIPELINE COMPLETED SUCCESSFULLY!\")\n",
        "\n",
        "        # Print best hyperparameters\n",
        "        print(f\"\\nBest Hyperparameters:\")\n",
        "        for param, value in results['best_hyperparams'].items():\n",
        "            print(f\"  {param}: {value}\")\n",
        "\n",
        "        # Final performance summary\n",
        "        cv_metrics = results['cv_metrics']\n",
        "        print(f\"\\n📊 FINAL PERFORMANCE SUMMARY:\")\n",
        "        print(f\"  RMSE: {cv_metrics['RMSE_mean']:.4f} ± {cv_metrics['RMSE_std']:.4f}\")\n",
        "        print(f\"  MSE:  {cv_metrics['MSE_mean']:.4f} ± {cv_metrics['MSE_std']:.4f}\")\n",
        "        print(f\"  Accuracy@0.5: {cv_metrics['Acc@0.5_mean']:.4f} ± {cv_metrics['Acc@0.5_std']:.4f}\")\n",
        "        print(f\"  Accuracy@1.0: {cv_metrics['Acc@1.0_mean']:.4f} ± {cv_metrics['Acc@1.0_std']:.4f}\")\n",
        "        print(f\"  Accuracy@1.5: {cv_metrics['Acc@1.5_mean']:.4f} ± {cv_metrics['Acc@1.5_std']:.4f}\")\n",
        "\n",
        "    else:\n",
        "        print(\"❌ Enhanced pipeline failed\")\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbX0a-xDG0ym"
      },
      "outputs": [],
      "source": [
        "class AdvancedOversamplingMixin:\n",
        "    \"\"\"Advanced oversampling techniques for imbalanced regression\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.oversampling_methods = {\n",
        "            'smote': SMOTE(random_state=42),\n",
        "            'adasyn': ADASYN(random_state=42),\n",
        "            'borderline_smote': BorderlineSMOTE(random_state=42),\n",
        "            'smote_enn': SMOTEENN(random_state=42),\n",
        "            'smote_tomek': SMOTETomek(random_state=42)\n",
        "        }\n",
        "\n",
        "    def apply_regression_oversampling(self, X: np.ndarray, y: np.ndarray,\n",
        "                                    method: str = 'smote_tomek') -> Tuple[np.ndarray, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Apply oversampling for regression by converting to classification temporarily\n",
        "        \"\"\"\n",
        "        print(f\"Applying {method} oversampling...\")\n",
        "\n",
        "        # Convert continuous targets to ordinal classes for oversampling\n",
        "        y_classes = np.round(y).astype(int) - 1  # Convert to 0-9 classes\n",
        "        y_classes = np.clip(y_classes, 0, 9)  # Ensure valid range\n",
        "\n",
        "        # Show original distribution\n",
        "        original_counts = np.bincount(y_classes, minlength=10)\n",
        "        print(f\"  Original class distribution: {original_counts}\")\n",
        "\n",
        "        try:\n",
        "            # Apply oversampling\n",
        "            if method in self.oversampling_methods:\n",
        "                X_resampled, y_classes_resampled = self.oversampling_methods[method].fit_resample(X, y_classes)\n",
        "\n",
        "                # Map back to original continuous targets by finding nearest neighbors\n",
        "                y_resampled = []\n",
        "                for new_class in y_classes_resampled:\n",
        "                    # Find original targets with this class\n",
        "                    class_mask = (y_classes == new_class)\n",
        "                    if np.any(class_mask):\n",
        "                        class_targets = y[class_mask]\n",
        "                        # Randomly sample from original targets in this class\n",
        "                        y_resampled.append(np.random.choice(class_targets))\n",
        "                    else:\n",
        "                        # Fallback: use class center\n",
        "                        y_resampled.append(new_class + 1.0)\n",
        "\n",
        "                y_resampled = np.array(y_resampled)\n",
        "\n",
        "                # Show new distribution\n",
        "                new_counts = np.bincount(y_classes_resampled, minlength=10)\n",
        "                print(f\"  Resampled class distribution: {new_counts}\")\n",
        "                print(f\"  Data size: {len(X)} -> {len(X_resampled)} (+{len(X_resampled)-len(X)})\")\n",
        "\n",
        "                return X_resampled, y_resampled\n",
        "\n",
        "            else:\n",
        "                print(f\"  Unknown method {method}, using original data\")\n",
        "                return X, y\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Oversampling failed: {str(e)}, using original data\")\n",
        "            return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Mlk-0TwG7Hc"
      },
      "outputs": [],
      "source": [
        "def compute_comprehensive_metrics(y_true: np.ndarray, y_pred: np.ndarray) -> Dict[str, float]:\n",
        "    \"\"\"Compute comprehensive metrics suitable for academic papers\"\"\"\n",
        "\n",
        "    # Basic regression metrics\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "    # Normalized metrics\n",
        "    nmse = mse / np.var(y_true)  # Normalized MSE\n",
        "    nmae = mae / np.mean(np.abs(y_true - np.mean(y_true)))  # Normalized MAE\n",
        "\n",
        "    # Error statistics\n",
        "    errors = y_pred - y_true\n",
        "    abs_errors = np.abs(errors)\n",
        "\n",
        "    # Percentage-based errors\n",
        "    mape = np.mean(np.abs(errors / y_true)) * 100  # Mean Absolute Percentage Error\n",
        "    smape = np.mean(2 * np.abs(errors) / (np.abs(y_true) + np.abs(y_pred))) * 100  # Symmetric MAPE\n",
        "\n",
        "    # Accuracy within tolerance levels (clinical relevance)\n",
        "    acc_0_25 = np.mean(abs_errors <= 0.25)  # Within 0.25 FMS points\n",
        "    acc_0_5 = np.mean(abs_errors <= 0.5)    # Within 0.5 FMS points\n",
        "    acc_0_75 = np.mean(abs_errors <= 0.75)  # Within 0.75 FMS points\n",
        "    acc_1_0 = np.mean(abs_errors <= 1.0)    # Within 1.0 FMS points\n",
        "    acc_1_25 = np.mean(abs_errors <= 1.25)  # Within 1.25 FMS points\n",
        "    acc_1_5 = np.mean(abs_errors <= 1.5)    # Within 1.5 FMS points\n",
        "    acc_2_0 = np.mean(abs_errors <= 2.0)    # Within 2.0 FMS points\n",
        "\n",
        "    # Clinical significance metrics\n",
        "    # Functional classes: 1-3 (severe), 4-6 (moderate), 7-10 (mild)\n",
        "    y_true_class = np.digitize(y_true, bins=[0, 3.5, 6.5, 10.1]) - 1\n",
        "    y_pred_class = np.digitize(y_pred, bins=[0, 3.5, 6.5, 10.1]) - 1\n",
        "\n",
        "    clinical_accuracy = np.mean(y_true_class == y_pred_class)\n",
        "\n",
        "    # Within-class accuracy (predictions within same functional class)\n",
        "    within_class_acc = clinical_accuracy\n",
        "\n",
        "    # Adjacent class tolerance (predictions within ±1 functional class)\n",
        "    adj_class_acc = np.mean(np.abs(y_true_class - y_pred_class) <= 1)\n",
        "\n",
        "    # Statistical measures\n",
        "    pearson_r, _ = stats.pearsonr(y_true, y_pred)\n",
        "    spearman_rho, _ = stats.spearmanr(y_true, y_pred)\n",
        "\n",
        "    # Bias and precision\n",
        "    bias = np.mean(errors)\n",
        "    precision_sd = np.std(errors)\n",
        "\n",
        "    # Limits of agreement (Bland-Altman)\n",
        "    loa_upper = bias + 1.96 * precision_sd\n",
        "    loa_lower = bias - 1.96 * precision_sd\n",
        "\n",
        "    # Index of Agreement (Willmott, 1981)\n",
        "    numerator = np.sum((y_pred - y_true) ** 2)\n",
        "    denominator = np.sum((np.abs(y_pred - np.mean(y_true)) + np.abs(y_true - np.mean(y_true))) ** 2)\n",
        "    index_of_agreement = 1 - (numerator / denominator) if denominator != 0 else 0\n",
        "\n",
        "    # Lin's Concordance Correlation Coefficient\n",
        "    mean_true = np.mean(y_true)\n",
        "    mean_pred = np.mean(y_pred)\n",
        "    var_true = np.var(y_true, ddof=1)\n",
        "    var_pred = np.var(y_pred, ddof=1)\n",
        "\n",
        "    numerator_ccc = 2 * pearson_r * np.sqrt(var_true) * np.sqrt(var_pred)\n",
        "    denominator_ccc = var_true + var_pred + (mean_true - mean_pred) ** 2\n",
        "    lin_ccc = numerator_ccc / denominator_ccc if denominator_ccc != 0 else 0\n",
        "\n",
        "    return {\n",
        "        # Primary regression metrics\n",
        "        'RMSE': rmse,\n",
        "        'MAE': mae,\n",
        "        'MSE': mse,\n",
        "        'R²': r2,\n",
        "        'NMSE': nmse,\n",
        "        'NMAE': nmae,\n",
        "\n",
        "        # Percentage errors\n",
        "        'MAPE': mape,\n",
        "        'SMAPE': smape,\n",
        "\n",
        "        # Clinical accuracy metrics\n",
        "        'Acc@0.25': acc_0_25,\n",
        "        'Acc@0.5': acc_0_5,\n",
        "        'Acc@0.75': acc_0_75,\n",
        "        'Acc@1.0': acc_1_0,\n",
        "        'Acc@1.25': acc_1_25,\n",
        "        'Acc@1.5': acc_1_5,\n",
        "        'Acc@2.0': acc_2_0,\n",
        "\n",
        "        # Functional class metrics\n",
        "        'Clinical_Accuracy': clinical_accuracy,\n",
        "        'Within_Class_Acc': within_class_acc,\n",
        "        'Adjacent_Class_Acc': adj_class_acc,\n",
        "\n",
        "        # Statistical measures\n",
        "        'Pearson_r': pearson_r,\n",
        "        'Spearman_ρ': spearman_rho,\n",
        "        'Lin_CCC': lin_ccc,\n",
        "        'Index_Agreement': index_of_agreement,\n",
        "\n",
        "        # Bias and precision\n",
        "        'Bias': bias,\n",
        "        'Precision_SD': precision_sd,\n",
        "        'LoA_Upper': loa_upper,\n",
        "        'LoA_Lower': loa_lower,\n",
        "\n",
        "        # Error percentiles\n",
        "        'Error_P50': np.percentile(abs_errors, 50),\n",
        "        'Error_P75': np.percentile(abs_errors, 75),\n",
        "        'Error_P90': np.percentile(abs_errors, 90),\n",
        "        'Error_P95': np.percentile(abs_errors, 95)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kM7BV8eqG9M4"
      },
      "outputs": [],
      "source": [
        "class EnhancedTimeSeriesProcessor(AdvancedOversamplingMixin):\n",
        "    \"\"\"Enhanced processor with advanced oversampling and contextual features\"\"\"\n",
        "\n",
        "    def __init__(self, window_size: int = 60, overlap: float = 0.5, oversampling_method: str = 'smote_tomek'):\n",
        "        super().__init__()\n",
        "        self.window_size = window_size\n",
        "        self.overlap = overlap\n",
        "        self.oversampling_method = oversampling_method\n",
        "        self.scaler = RobustScaler()\n",
        "        self.outlier_detector = IsolationForest(contamination=0.1, random_state=42)\n",
        "\n",
        "    def identify_contextual_features(self, df: pd.DataFrame) -> Dict[str, List[str]]:\n",
        "        \"\"\"Identify contextual features mentioned as highly correlated with FMS\"\"\"\n",
        "\n",
        "        contextual_features = {\n",
        "            'timing_features': [],\n",
        "            'frame_features': [],\n",
        "            'eye_features': [],\n",
        "            'spatial_features': [],\n",
        "            'movement_features': []\n",
        "        }\n",
        "\n",
        "        # Search for contextual features (case insensitive)\n",
        "        for col in df.columns:\n",
        "            col_lower = col.lower()\n",
        "            if any(keyword in col_lower for keyword in ['eyeframe', 'eye_frame', 'eye']):\n",
        "                contextual_features['eye_features'].append(col)\n",
        "            elif any(keyword in col_lower for keyword in ['vivetiming', 'vive_timing', 'timing']):\n",
        "                contextual_features['timing_features'].append(col)\n",
        "            elif any(keyword in col_lower for keyword in ['frame', 'timestamp']):\n",
        "                contextual_features['frame_features'].append(col)\n",
        "            elif any(keyword in col_lower for keyword in ['position', 'pos', 'location', 'x', 'y', 'z']):\n",
        "                contextual_features['spatial_features'].append(col)\n",
        "            elif any(keyword in col_lower for keyword in ['velocity', 'vel', 'speed', 'acceleration', 'accel']):\n",
        "                contextual_features['movement_features'].append(col)\n",
        "\n",
        "        return contextual_features\n",
        "\n",
        "    def remove_outliers(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Remove outliers using Isolation Forest and statistical methods\"\"\"\n",
        "\n",
        "        print(\"Removing outliers...\")\n",
        "        original_len = len(df)\n",
        "\n",
        "        # Remove extreme FMS outliers (outside reasonable range)\n",
        "        df = df[(df['fms_score'] >= 1) & (df['fms_score'] <= 10)]\n",
        "\n",
        "        # Get numeric feature columns\n",
        "        metadata_cols = {\n",
        "            'participant_id', 'timestamp', 'fms', 'fms_label', 'fms_score',\n",
        "            'segment_id', 'dataset', 'folder_name', 'frame'\n",
        "        }\n",
        "        numeric_cols = [col for col in df.columns if col not in metadata_cols\n",
        "                       and df[col].dtype in [np.float64, np.float32, np.int64, np.int32]]\n",
        "\n",
        "        if numeric_cols:\n",
        "            # Prepare data for outlier detection\n",
        "            feature_data = df[numeric_cols].fillna(0).values\n",
        "\n",
        "            # Use Isolation Forest for multivariate outlier detection\n",
        "            outlier_labels = self.outlier_detector.fit_predict(feature_data)\n",
        "            df = df[outlier_labels == 1]  # Keep inliers only\n",
        "\n",
        "        # Remove statistical outliers using IQR method for FMS scores\n",
        "        Q1 = df['fms_score'].quantile(0.25)\n",
        "        Q3 = df['fms_score'].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "        df = df[(df['fms_score'] >= lower_bound) & (df['fms_score'] <= upper_bound)]\n",
        "\n",
        "        print(f\"  Removed {original_len - len(df)} outliers ({(original_len - len(df))/original_len*100:.1f}%)\")\n",
        "        print(f\"  Remaining samples: {len(df)}\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    def create_contextual_features(self, window_data: pd.DataFrame,\n",
        "                                 contextual_features: Dict[str, List[str]]) -> np.ndarray:\n",
        "        \"\"\"Create enhanced features including contextual information\"\"\"\n",
        "\n",
        "        # Standard statistical features\n",
        "        metadata_cols = {\n",
        "            'participant_id', 'timestamp', 'fms', 'fms_label', 'fms_score',\n",
        "            'segment_id', 'dataset', 'folder_name', 'frame'\n",
        "        }\n",
        "\n",
        "        feature_cols = [col for col in window_data.columns if col not in metadata_cols]\n",
        "        numeric_cols = [col for col in feature_cols\n",
        "                       if window_data[col].dtype in [np.float64, np.float32, np.int64, np.int32]]\n",
        "\n",
        "        if not numeric_cols:\n",
        "            return np.array([0.0] * 50)\n",
        "\n",
        "        numeric_data = window_data[numeric_cols].fillna(0).values\n",
        "        numeric_data = np.nan_to_num(numeric_data, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "        features = []\n",
        "\n",
        "        # Basic statistical features\n",
        "        if len(numeric_data) > 0:\n",
        "            features.extend([\n",
        "                np.mean(numeric_data),\n",
        "                np.std(numeric_data),\n",
        "                np.min(numeric_data),\n",
        "                np.max(numeric_data),\n",
        "                np.median(numeric_data),\n",
        "                np.percentile(numeric_data, 25),\n",
        "                np.percentile(numeric_data, 75),\n",
        "                stats.skew(numeric_data.flatten()),\n",
        "                stats.kurtosis(numeric_data.flatten()),\n",
        "                np.ptp(numeric_data)  # Range\n",
        "            ])\n",
        "        else:\n",
        "            features.extend([0.0] * 10)\n",
        "\n",
        "        # Temporal features\n",
        "        if len(numeric_data) > 1:\n",
        "            # Linear trend\n",
        "            time_points = np.arange(len(numeric_data))\n",
        "            slopes = []\n",
        "            for col_idx in range(numeric_data.shape[1]):\n",
        "                try:\n",
        "                    slope = np.polyfit(time_points, numeric_data[:, col_idx], 1)[0]\n",
        "                    slopes.append(slope)\n",
        "                except:\n",
        "                    slopes.append(0.0)\n",
        "\n",
        "            features.extend([\n",
        "                np.mean(slopes),\n",
        "                np.std(slopes),\n",
        "                np.max(slopes),\n",
        "                np.min(slopes)\n",
        "            ])\n",
        "\n",
        "            # Velocity and acceleration\n",
        "            velocity = np.diff(numeric_data, axis=0)\n",
        "            if len(velocity) > 0:\n",
        "                features.extend([\n",
        "                    np.mean(velocity),\n",
        "                    np.std(velocity),\n",
        "                    np.mean(np.abs(velocity))\n",
        "                ])\n",
        "            else:\n",
        "                features.extend([0.0] * 3)\n",
        "\n",
        "            # Acceleration\n",
        "            if len(velocity) > 1:\n",
        "                acceleration = np.diff(velocity, axis=0)\n",
        "                features.extend([\n",
        "                    np.mean(acceleration),\n",
        "                    np.std(acceleration)\n",
        "                ])\n",
        "            else:\n",
        "                features.extend([0.0] * 2)\n",
        "        else:\n",
        "            features.extend([0.0] * 9)\n",
        "\n",
        "        # Contextual features (enhanced for highly correlated features)\n",
        "        contextual_feature_values = []\n",
        "\n",
        "        # Process contextual features with special attention\n",
        "        for feature_type, feature_list in contextual_features.items():\n",
        "            available_features = [f for f in feature_list if f in window_data.columns]\n",
        "\n",
        "            if available_features:\n",
        "                contextual_data = window_data[available_features].fillna(0).values\n",
        "                if len(contextual_data) > 0:\n",
        "                    # Enhanced statistics for contextual features\n",
        "                    contextual_feature_values.extend([\n",
        "                        np.mean(contextual_data),\n",
        "                        np.std(contextual_data),\n",
        "                        np.max(contextual_data) - np.min(contextual_data),  # Range\n",
        "                        np.mean(np.diff(contextual_data, axis=0)) if len(contextual_data) > 1 else 0.0,  # Trend\n",
        "                    ])\n",
        "                else:\n",
        "                    contextual_feature_values.extend([0.0] * 4)\n",
        "            else:\n",
        "                contextual_feature_values.extend([0.0] * 4)\n",
        "\n",
        "        features.extend(contextual_feature_values)\n",
        "\n",
        "        # Frequency domain features (if window is large enough)\n",
        "        if len(numeric_data) > 8:\n",
        "            # Simple frequency features using FFT\n",
        "            try:\n",
        "                fft_features = []\n",
        "                for col_idx in range(min(3, numeric_data.shape[1])):  # Limit to first 3 columns\n",
        "                    fft = np.fft.fft(numeric_data[:, col_idx])\n",
        "                    fft_magnitude = np.abs(fft)\n",
        "                    fft_features.extend([\n",
        "                        np.mean(fft_magnitude[:len(fft_magnitude)//2]),  # Mean of positive frequencies\n",
        "                        np.argmax(fft_magnitude[:len(fft_magnitude)//2])  # Dominant frequency\n",
        "                    ])\n",
        "\n",
        "                features.extend(fft_features)\n",
        "            except:\n",
        "                features.extend([0.0] * 6)\n",
        "        else:\n",
        "            features.extend([0.0] * 6)\n",
        "\n",
        "        return np.array(features, dtype=np.float32)\n",
        "\n",
        "    def create_balanced_sequences(self, sequences: List[Dict]) -> List[Dict]:\n",
        "        \"\"\"Create balanced dataset using oversampling for minority classes\"\"\"\n",
        "\n",
        "        print(\"Balancing dataset...\")\n",
        "\n",
        "        # Convert continuous FMS scores to ordinal classes for balancing\n",
        "        fms_scores = [seq['target_fms'] for seq in sequences]\n",
        "        fms_classes = [int(np.round(score)) - 1 for score in fms_scores]  # 0-9 classes\n",
        "\n",
        "        # Count class distribution\n",
        "        class_counts = Counter(fms_classes)\n",
        "        print(f\"  Original distribution: {dict(sorted(class_counts.items()))}\")\n",
        "\n",
        "        # Find target count (median or mean of class counts)\n",
        "        target_count = int(np.median(list(class_counts.values())))\n",
        "\n",
        "        # Group sequences by class\n",
        "        class_sequences = defaultdict(list)\n",
        "        for seq, cls in zip(sequences, fms_classes):\n",
        "            class_sequences[cls].append(seq)\n",
        "\n",
        "        # Balance by oversampling minority classes\n",
        "        balanced_sequences = []\n",
        "\n",
        "        for cls in range(10):  # FMS classes 1-10 (0-9 indexed)\n",
        "            if cls in class_sequences:\n",
        "                cls_sequences = class_sequences[cls]\n",
        "                current_count = len(cls_sequences)\n",
        "\n",
        "                # Add original sequences\n",
        "                balanced_sequences.extend(cls_sequences)\n",
        "\n",
        "                # Oversample if needed\n",
        "                if current_count < target_count:\n",
        "                    oversample_count = target_count - current_count\n",
        "                    oversampled = np.random.choice(cls_sequences, size=oversample_count, replace=True)\n",
        "                    balanced_sequences.extend(oversampled)\n",
        "\n",
        "        # Shuffle the balanced dataset\n",
        "        np.random.shuffle(balanced_sequences)\n",
        "\n",
        "        # Show new distribution\n",
        "        new_fms_classes = [int(np.round(seq['target_fms'])) - 1 for seq in balanced_sequences]\n",
        "        new_class_counts = Counter(new_fms_classes)\n",
        "        print(f\"  Balanced distribution: {dict(sorted(new_class_counts.items()))}\")\n",
        "        print(f\"  Total sequences: {len(sequences)} -> {len(balanced_sequences)}\")\n",
        "\n",
        "        return balanced_sequences\n",
        "\n",
        "    def process_all_data(self, vrnet_df: pd.DataFrame, vrwalking_df: pd.DataFrame) -> Tuple:\n",
        "        \"\"\"Process all data with advanced oversampling\"\"\"\n",
        "\n",
        "        print(\"Processing data with advanced oversampling...\")\n",
        "\n",
        "        # Remove outliers from each dataset\n",
        "        vrnet_df = self.remove_outliers(vrnet_df)\n",
        "        vrwalking_df = self.remove_outliers(vrwalking_df)\n",
        "\n",
        "        # Combine datasets\n",
        "        combined_df = pd.concat([vrnet_df, vrwalking_df], ignore_index=True)\n",
        "        combined_df = combined_df.dropna(subset=['fms_score'])\n",
        "\n",
        "        # Identify contextual features\n",
        "        contextual_features = self.identify_contextual_features(combined_df)\n",
        "        print(f\"  Identified contextual features: {contextual_features}\")\n",
        "\n",
        "        all_sequences = []\n",
        "\n",
        "        # Process each participant\n",
        "        for participant_id in combined_df['participant_id'].unique():\n",
        "            participant_df = combined_df[combined_df['participant_id'] == participant_id]\n",
        "\n",
        "            if len(participant_df) < self.window_size:\n",
        "                continue\n",
        "\n",
        "            participant_df = participant_df.sort_values('timestamp').reset_index(drop=True)\n",
        "\n",
        "            # Create sequences with overlap\n",
        "            step_size = max(1, int(self.window_size * (1 - self.overlap)))\n",
        "\n",
        "            for i in range(0, len(participant_df) - self.window_size + 1, step_size):\n",
        "                window_data = participant_df.iloc[i:i + self.window_size]\n",
        "                target_fms = window_data['fms_score'].iloc[-1]\n",
        "\n",
        "                if pd.isna(target_fms):\n",
        "                    continue\n",
        "\n",
        "                # Create enhanced features\n",
        "                features = self.create_contextual_features(window_data, contextual_features)\n",
        "\n",
        "                all_sequences.append({\n",
        "                    'features': features,\n",
        "                    'target_fms': float(target_fms),\n",
        "                    'participant_id': participant_id,\n",
        "                    'dataset': participant_df['dataset'].iloc[0]\n",
        "                })\n",
        "\n",
        "        print(f\"Created {len(all_sequences)} sequences before oversampling\")\n",
        "\n",
        "        # Extract arrays\n",
        "        X = np.array([seq['features'] for seq in all_sequences])\n",
        "        y = np.array([seq['target_fms'] for seq in all_sequences])\n",
        "        participant_ids = [seq['participant_id'] for seq in all_sequences]\n",
        "        datasets = [seq['dataset'] for seq in all_sequences]\n",
        "\n",
        "        # Apply advanced oversampling\n",
        "        X_oversampled, y_oversampled = self.apply_regression_oversampling(\n",
        "            X, y, method=self.oversampling_method\n",
        "        )\n",
        "\n",
        "        # Extend participant_ids and datasets to match oversampled data\n",
        "        if len(X_oversampled) > len(X):\n",
        "            # Generate new participant IDs for synthetic samples\n",
        "            n_synthetic = len(X_oversampled) - len(X)\n",
        "            synthetic_pids = [f\"synthetic_{i}\" for i in range(n_synthetic)]\n",
        "            synthetic_datasets = [\"synthetic\"] * n_synthetic\n",
        "\n",
        "            participant_ids_extended = participant_ids + synthetic_pids\n",
        "            datasets_extended = datasets + synthetic_datasets\n",
        "        else:\n",
        "            participant_ids_extended = participant_ids[:len(X_oversampled)]\n",
        "            datasets_extended = datasets[:len(X_oversampled)]\n",
        "\n",
        "        # Scale features\n",
        "        print(f\"Scaling {X_oversampled.shape[1]} features...\")\n",
        "        X_scaled = self.scaler.fit_transform(X_oversampled)\n",
        "\n",
        "        print(f\"Final oversampled dataset: {X_scaled.shape[0]} sequences, {X_scaled.shape[1]} features\")\n",
        "        print(f\"FMS range: {y_oversampled.min():.2f} - {y_oversampled.max():.2f}\")\n",
        "\n",
        "        return X_scaled, y_oversampled, participant_ids_extended, datasets_extended"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcS2RXUuG_da"
      },
      "outputs": [],
      "source": [
        "class SimplifiedOrdinalLoss(nn.Module):\n",
        "    \"\"\"Simplified ordinal loss with focal weighting for class imbalance\"\"\"\n",
        "\n",
        "    def __init__(self, ordinal_weight: float = 0.7, regression_weight: float = 0.3,\n",
        "                 focal_alpha: float = 0.25, focal_gamma: float = 2.0):\n",
        "        super().__init__()\n",
        "        self.ordinal_weight = ordinal_weight\n",
        "        self.regression_weight = regression_weight\n",
        "        self.focal_alpha = focal_alpha\n",
        "        self.focal_gamma = focal_gamma\n",
        "\n",
        "    def focal_loss(self, class_probs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Focal loss for handling class imbalance\"\"\"\n",
        "        batch_size = class_probs.size(0)\n",
        "        num_classes = class_probs.size(1)\n",
        "\n",
        "        # Ensure targets are in valid range [1, 10] then convert to [0, 9]\n",
        "        targets_clamped = torch.clamp(targets, min=1.0, max=10.0)\n",
        "        target_classes = torch.clamp(torch.round(targets_clamped) - 1, 0, num_classes - 1).long()\n",
        "\n",
        "        # Ensure class_probs are valid probabilities\n",
        "        class_probs_safe = torch.clamp(class_probs, min=1e-7, max=1.0)\n",
        "        class_probs_safe = class_probs_safe / class_probs_safe.sum(dim=1, keepdim=True)\n",
        "\n",
        "        # Get probabilities for target classes\n",
        "        pt = class_probs_safe.gather(1, target_classes.unsqueeze(1)).squeeze(1)\n",
        "\n",
        "        # Focal loss computation\n",
        "        alpha_t = self.focal_alpha\n",
        "        focal_weight = alpha_t * (1 - pt) ** self.focal_gamma\n",
        "        focal_loss = -focal_weight * torch.log(pt + 1e-7)\n",
        "\n",
        "        return focal_loss.mean()\n",
        "\n",
        "    def ordinal_loss(self, class_probs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Ordinal loss using focal weighting\"\"\"\n",
        "        return self.focal_loss(class_probs, targets)\n",
        "\n",
        "    def forward(self, expected_values: torch.Tensor, regression_output: torch.Tensor,\n",
        "                class_probs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        # Clamp all inputs to safe ranges\n",
        "        expected_values = torch.clamp(expected_values, min=1.0, max=10.0)\n",
        "        regression_output = torch.clamp(regression_output, min=1.0, max=10.0)\n",
        "        targets = torch.clamp(targets, min=1.0, max=10.0)\n",
        "\n",
        "        # Ordinal loss with focal weighting\n",
        "        ord_loss = self.ordinal_loss(class_probs, targets)\n",
        "\n",
        "        # Regression loss with Huber loss (robust to outliers)\n",
        "        reg_loss = F.smooth_l1_loss(regression_output, targets)\n",
        "\n",
        "        # Combined prediction loss\n",
        "        combined_pred = 0.6 * expected_values + 0.4 * regression_output\n",
        "        combined_pred = torch.clamp(combined_pred, min=1.0, max=10.0)\n",
        "        combined_loss = F.smooth_l1_loss(combined_pred, targets)\n",
        "\n",
        "        # Total loss\n",
        "        total_loss = (self.ordinal_weight * ord_loss +\n",
        "                     self.regression_weight * reg_loss +\n",
        "                     0.2 * combined_loss)\n",
        "\n",
        "        return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_q-brOhIHCNT"
      },
      "outputs": [],
      "source": [
        "class EnhancedVRDataset(Dataset):\n",
        "    \"\"\"Enhanced dataset with advanced weighted sampling\"\"\"\n",
        "\n",
        "    def __init__(self, features: np.ndarray, targets: np.ndarray,\n",
        "                 participant_ids: List[str], datasets: List[str]):\n",
        "        self.features = torch.FloatTensor(features)\n",
        "        self.targets = torch.FloatTensor(targets)\n",
        "        self.participant_ids = participant_ids\n",
        "        self.datasets = datasets\n",
        "\n",
        "        # Create participant groups for CV\n",
        "        self.unique_participants = list(set(participant_ids))\n",
        "        self.participant_to_group = {pid: i for i, pid in enumerate(self.unique_participants)}\n",
        "        self.groups = [self.participant_to_group[pid] for pid in participant_ids]\n",
        "\n",
        "        # Calculate advanced sample weights\n",
        "        self.sample_weights = self._calculate_advanced_sample_weights()\n",
        "\n",
        "    def _calculate_advanced_sample_weights(self) -> torch.Tensor:\n",
        "        \"\"\"Calculate advanced sample weights considering both class imbalance and regression targets\"\"\"\n",
        "\n",
        "        # Method 1: Ordinal class-based weights\n",
        "        target_classes = torch.round(self.targets).long() - 1  # 0-9 classes\n",
        "        target_classes = torch.clamp(target_classes, 0, 9)\n",
        "\n",
        "        # Calculate class weights with smoothing\n",
        "        class_counts = torch.bincount(target_classes, minlength=10)\n",
        "        total_samples = len(target_classes)\n",
        "\n",
        "        # Smooth class counts to prevent extreme weights\n",
        "        smoothed_counts = class_counts.float() + 1.0\n",
        "        class_weights = total_samples / (len(smoothed_counts) * smoothed_counts)\n",
        "\n",
        "        # Method 2: Density-based weights for continuous targets\n",
        "        # Create bins for continuous targets\n",
        "        hist, bin_edges = np.histogram(self.targets.numpy(), bins=20)\n",
        "        bin_indices = np.digitize(self.targets.numpy(), bin_edges) - 1\n",
        "        bin_indices = np.clip(bin_indices, 0, len(hist) - 1)\n",
        "\n",
        "        # Calculate density weights\n",
        "        density_weights = 1.0 / (hist[bin_indices] + 1.0)  # Add 1 for smoothing\n",
        "        density_weights = density_weights / np.sum(density_weights) * len(density_weights)  # Normalize\n",
        "\n",
        "        # Combine both weighting schemes\n",
        "        class_weights_array = class_weights[target_classes].numpy()\n",
        "        combined_weights = 0.7 * class_weights_array + 0.3 * density_weights\n",
        "\n",
        "        return torch.FloatTensor(combined_weights)\n",
        "\n",
        "    def get_weighted_sampler(self) -> WeightedRandomSampler:\n",
        "        \"\"\"Get advanced weighted sampler\"\"\"\n",
        "        return WeightedRandomSampler(\n",
        "            weights=self.sample_weights,\n",
        "            num_samples=len(self.sample_weights),\n",
        "            replacement=True\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'features': self.features[idx],\n",
        "            'target': self.targets[idx],\n",
        "            'participant_id': self.participant_ids[idx],\n",
        "            'dataset': self.datasets[idx]\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdxtc1j1HFV2"
      },
      "outputs": [],
      "source": [
        "def train_enhanced_model(train_loader: DataLoader, val_loader: DataLoader,\n",
        "                        input_dim: int, hyperparams: Dict, num_epochs: int = 100,\n",
        "                        fold_idx: int = 0) -> Dict:\n",
        "    \"\"\"Train enhanced ordinal regression model with comprehensive metrics\"\"\"\n",
        "\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "    # Initialize model with hyperparameters\n",
        "    model = EnhancedOrdinalModel(\n",
        "        input_dim=input_dim,\n",
        "        hidden_dims=hyperparams.get('hidden_dims', [512, 256, 128, 64]),\n",
        "        dropout=hyperparams.get('dropout', 0.3)\n",
        "    ).to(device)\n",
        "\n",
        "    # Enhanced loss function with focal loss\n",
        "    criterion = SimplifiedOrdinalLoss(\n",
        "        ordinal_weight=hyperparams.get('ordinal_weight', 0.6),\n",
        "        regression_weight=hyperparams.get('regression_weight', 0.4),\n",
        "        focal_alpha=hyperparams.get('focal_alpha', 0.25),\n",
        "        focal_gamma=hyperparams.get('focal_gamma', 2.0)\n",
        "    )\n",
        "\n",
        "    # Optimizer with weight decay\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=hyperparams.get('lr', 1e-3),\n",
        "        weight_decay=hyperparams.get('weight_decay', 1e-4)\n",
        "    )\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "        optimizer,\n",
        "        max_lr=hyperparams.get('lr', 1e-3) * 2,\n",
        "        epochs=num_epochs,\n",
        "        steps_per_epoch=len(train_loader),\n",
        "        pct_start=0.3\n",
        "    )\n",
        "\n",
        "    best_val_rmse = float('inf')\n",
        "    patience = 30\n",
        "    patience_counter = 0\n",
        "\n",
        "    print(f\"\\nTraining Enhanced Fold {fold_idx + 1}...\")\n",
        "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "    # Training history\n",
        "    train_losses = []\n",
        "    val_rmses = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_batches = 0\n",
        "\n",
        "        for batch in train_loader:\n",
        "            features = batch['features'].to(device)\n",
        "            targets = batch['target'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            expected_values, regression_output, class_probs = model(features)\n",
        "            loss = criterion(expected_values, regression_output, class_probs, targets)\n",
        "\n",
        "            # Check for NaN loss\n",
        "            if torch.isnan(loss):\n",
        "                continue\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            train_batches += 1\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_predictions = []\n",
        "        val_targets = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                features = batch['features'].to(device)\n",
        "                targets = batch['target'].to(device)\n",
        "\n",
        "                predictions = model.predict_continuous(features)\n",
        "                val_predictions.extend(predictions.cpu().numpy())\n",
        "                val_targets.extend(targets.cpu().numpy())\n",
        "\n",
        "        if not val_predictions:\n",
        "            continue\n",
        "\n",
        "        # Calculate comprehensive metrics\n",
        "        val_metrics = compute_comprehensive_metrics(np.array(val_targets), np.array(val_predictions))\n",
        "        val_rmse = val_metrics['RMSE']\n",
        "\n",
        "        train_losses.append(train_loss / max(train_batches, 1))\n",
        "        val_rmses.append(val_rmse)\n",
        "\n",
        "        # Print progress with key metrics\n",
        "        if epoch % 20 == 0 or epoch == num_epochs - 1:\n",
        "            print(f'  Epoch {epoch+1:3d}: Loss: {train_loss/max(train_batches, 1):.4f}, '\n",
        "                  f'RMSE: {val_rmse:.4f}, MAE: {val_metrics[\"MAE\"]:.4f}, '\n",
        "                  f'Acc@1.0: {val_metrics[\"Acc@1.0\"]:.4f}, R²: {val_metrics[\"R²\"]:.4f}')\n",
        "\n",
        "        # Early stopping\n",
        "        if val_rmse < best_val_rmse:\n",
        "            best_val_rmse = val_rmse\n",
        "            patience_counter = 0\n",
        "            torch.save(model.state_dict(), f'best_enhanced_model_fold_{fold_idx}.pth')\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(f'    Early stopping at epoch {epoch+1}')\n",
        "                break\n",
        "\n",
        "    # Load best model and get final predictions\n",
        "    try:\n",
        "        model.load_state_dict(torch.load(f'best_enhanced_model_fold_{fold_idx}.pth'))\n",
        "    except:\n",
        "        print(f\"    Warning: Could not load best model, using current state\")\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    final_predictions = []\n",
        "    final_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            features = batch['features'].to(device)\n",
        "            targets = batch['target'].to(device)\n",
        "\n",
        "            predictions = model.predict_continuous(features)\n",
        "            final_predictions.extend(predictions.cpu().numpy())\n",
        "            final_targets.extend(targets.cpu().numpy())\n",
        "\n",
        "    if final_predictions:\n",
        "        final_metrics = compute_comprehensive_metrics(np.array(final_targets), np.array(final_predictions))\n",
        "\n",
        "        print(f'  Final Fold {fold_idx + 1} Results:')\n",
        "        print(f'    RMSE: {final_metrics[\"RMSE\"]:.4f}, MAE: {final_metrics[\"MAE\"]:.4f}, R²: {final_metrics[\"R²\"]:.4f}')\n",
        "        print(f'    Acc@0.5: {final_metrics[\"Acc@0.5\"]:.4f}, Acc@1.0: {final_metrics[\"Acc@1.0\"]:.4f}, Acc@1.5: {final_metrics[\"Acc@1.5\"]:.4f}')\n",
        "        print(f'    Clinical Accuracy: {final_metrics[\"Clinical_Accuracy\"]:.4f}, Lin CCC: {final_metrics[\"Lin_CCC\"]:.4f}')\n",
        "    else:\n",
        "        print(f'  Warning: No valid final predictions for fold {fold_idx + 1}')\n",
        "        final_metrics = {key: 0.0 for key in ['RMSE', 'MAE', 'MSE', 'R²', 'Acc@0.5', 'Acc@1.0', 'Acc@1.5',\n",
        "                                              'Clinical_Accuracy', 'Lin_CCC', 'Pearson_r', 'MAPE', 'SMAPE']}\n",
        "        final_predictions = [5.0] * len(val_loader.dataset)\n",
        "        final_targets = [5.0] * len(val_loader.dataset)\n",
        "\n",
        "    return {\n",
        "        'predictions': final_predictions,\n",
        "        'targets': final_targets,\n",
        "        'metrics': final_metrics,\n",
        "        'train_losses': train_losses,\n",
        "        'val_rmses': val_rmses\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAfy2R6-HHnc"
      },
      "outputs": [],
      "source": [
        "def create_academic_visualizations(fold_results: List[Dict], cv_metrics: Dict):\n",
        "    \"\"\"Create publication-quality visualizations with comprehensive metrics\"\"\"\n",
        "\n",
        "    # Combine all results\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "    all_train_losses = []\n",
        "    all_val_rmses = []\n",
        "\n",
        "    for fold_result in fold_results:\n",
        "        all_predictions.extend(fold_result['predictions'])\n",
        "        all_targets.extend(fold_result['targets'])\n",
        "        all_train_losses.extend(fold_result['train_losses'])\n",
        "        all_val_rmses.extend(fold_result['val_rmses'])\n",
        "\n",
        "    all_predictions = np.array(all_predictions)\n",
        "    all_targets = np.array(all_targets)\n",
        "    residuals = all_predictions - all_targets\n",
        "\n",
        "    # Create publication-ready plots\n",
        "    plt.style.use('seaborn-v0_8-whitegrid')\n",
        "    fig = plt.figure(figsize=(24, 20))\n",
        "\n",
        "    # 1. Main Regression Plot with Statistics\n",
        "    ax1 = plt.subplot(4, 4, 1)\n",
        "    plt.scatter(all_targets, all_predictions, alpha=0.6, s=25, c='steelblue', edgecolors='navy', linewidth=0.5)\n",
        "\n",
        "    # Perfect prediction line\n",
        "    min_val, max_val = min(all_targets.min(), all_predictions.min()), max(all_targets.max(), all_predictions.max())\n",
        "    plt.plot([min_val, max_val], [min_val, max_val], 'r-', lw=2, label='Perfect Prediction')\n",
        "\n",
        "    # Regression line\n",
        "    z = np.polyfit(all_targets, all_predictions, 1)\n",
        "    p = np.poly1d(z)\n",
        "    plt.plot(all_targets, p(all_targets), 'g--', lw=2, label=f'Regression Line (y={z[0]:.2f}x+{z[1]:.2f})')\n",
        "\n",
        "    plt.xlabel('True FMS Scores', fontsize=12)\n",
        "    plt.ylabel('Predicted FMS Scores', fontsize=12)\n",
        "    plt.title('FMS Prediction Performance', fontsize=14, fontweight='bold')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # Add statistics box\n",
        "    stats_text = f'RMSE = {cv_metrics[\"RMSE_mean\"]:.3f}\\nMAE = {cv_metrics[\"MAE_mean\"]:.3f}\\nR² = {cv_metrics[\"R²_mean\"]:.3f}\\nLin CCC = {cv_metrics[\"Lin_CCC_mean\"]:.3f}'\n",
        "    plt.text(0.05, 0.95, stats_text, transform=ax1.transAxes, fontsize=10,\n",
        "             verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
        "\n",
        "    # 2. Bland-Altman Plot\n",
        "    ax2 = plt.subplot(4, 4, 2)\n",
        "    mean_values = (all_targets + all_predictions) / 2\n",
        "    differences = all_predictions - all_targets\n",
        "\n",
        "    plt.scatter(mean_values, differences, alpha=0.6, s=25, c='lightcoral', edgecolors='darkred', linewidth=0.5)\n",
        "\n",
        "    # Mean difference line\n",
        "    mean_diff = np.mean(differences)\n",
        "    plt.axhline(y=mean_diff, color='blue', linestyle='-', lw=2, label=f'Mean Bias = {mean_diff:.3f}')\n",
        "\n",
        "    # Limits of agreement\n",
        "    std_diff = np.std(differences)\n",
        "    upper_loa = mean_diff + 1.96 * std_diff\n",
        "    lower_loa = mean_diff - 1.96 * std_diff\n",
        "\n",
        "    plt.axhline(y=upper_loa, color='red', linestyle='--', lw=2, label=f'Upper LoA = {upper_loa:.3f}')\n",
        "    plt.axhline(y=lower_loa, color='red', linestyle='--', lw=2, label=f'Lower LoA = {lower_loa:.3f}')\n",
        "\n",
        "    plt.xlabel('Mean of True and Predicted FMS', fontsize=12)\n",
        "    plt.ylabel('Difference (Predicted - True)', fontsize=12)\n",
        "    plt.title('Bland-Altman Plot', fontsize=14, fontweight='bold')\n",
        "    plt.legend(fontsize=9)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # 3. Residuals vs Fitted\n",
        "    ax3 = plt.subplot(4, 4, 3)\n",
        "    plt.scatter(all_predictions, residuals, alpha=0.6, s=25, c='lightgreen', edgecolors='darkgreen', linewidth=0.5)\n",
        "    plt.axhline(y=0, color='r', linestyle='--', lw=2)\n",
        "\n",
        "    plt.xlabel('Predicted FMS Scores', fontsize=12)\n",
        "    plt.ylabel('Residuals', fontsize=12)\n",
        "    plt.title('Residuals vs Fitted Values', fontsize=14, fontweight='bold')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # 4. Q-Q Plot\n",
        "    ax4 = plt.subplot(4, 4, 4)\n",
        "    stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
        "    plt.title('Q-Q Plot of Residuals', fontsize=14, fontweight='bold')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # 5. Accuracy Metrics Bar Chart\n",
        "    ax5 = plt.subplot(4, 4, 5)\n",
        "    accuracy_metrics = ['Acc@0.25', 'Acc@0.5', 'Acc@0.75', 'Acc@1.0', 'Acc@1.25', 'Acc@1.5', 'Acc@2.0']\n",
        "    accuracy_values = [cv_metrics[f'{metric}_mean'] for metric in accuracy_metrics]\n",
        "    accuracy_stds = [cv_metrics[f'{metric}_std'] for metric in accuracy_metrics]\n",
        "\n",
        "    colors = plt.cm.RdYlBu_r(np.linspace(0.2, 0.8, len(accuracy_metrics)))\n",
        "    bars = plt.bar(range(len(accuracy_metrics)), accuracy_values, yerr=accuracy_stds,\n",
        "                   capsize=5, alpha=0.8, color=colors, edgecolor='black', linewidth=1)\n",
        "\n",
        "    plt.xlabel('Tolerance Levels', fontsize=12)\n",
        "    plt.ylabel('Accuracy', fontsize=12)\n",
        "    plt.title('Accuracy at Different Tolerance Levels', fontsize=14, fontweight='bold')\n",
        "    plt.xticks(range(len(accuracy_metrics)), [m.replace('Acc@', '±') for m in accuracy_metrics], rotation=45)\n",
        "    plt.ylim(0, 1)\n",
        "    plt.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for i, (bar, val, std) in enumerate(zip(bars, accuracy_values, accuracy_stds)):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
        "                f'{val:.2f}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
        "\n",
        "    # 6. Clinical Functional Class Analysis\n",
        "    ax6 = plt.subplot(4, 4, 6)\n",
        "    # Define functional classes: Severe (1-3), Moderate (4-6), Mild (7-10)\n",
        "    class_bounds = [0, 3.5, 6.5, 10.1]\n",
        "    class_labels = ['Severe\\n(1-3)', 'Moderate\\n(4-6)', 'Mild\\n(7-10)']\n",
        "\n",
        "    true_classes = np.digitize(all_targets, class_bounds) - 1\n",
        "    pred_classes = np.digitize(all_predictions, class_bounds) - 1\n",
        "\n",
        "    # Create confusion matrix for functional classes\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    cm = confusion_matrix(true_classes, pred_classes, labels=[0, 1, 2])\n",
        "\n",
        "    # Plot heatmap\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_labels, yticklabels=class_labels,\n",
        "                cbar_kws={'label': 'Count'})\n",
        "    plt.xlabel('Predicted Functional Class', fontsize=12)\n",
        "    plt.ylabel('True Functional Class', fontsize=12)\n",
        "    plt.title('Functional Class Confusion Matrix', fontsize=14, fontweight='bold')\n",
        "\n",
        "    # 7. Error Distribution by FMS Score Ranges\n",
        "    ax7 = plt.subplot(4, 4, 7)\n",
        "    fms_ranges = [(1, 3), (3, 5), (5, 7), (7, 10)]\n",
        "    range_errors = []\n",
        "    range_labels = []\n",
        "    range_colors = ['#ff9999', '#66b3ff', '#99ff99', '#ffcc99']\n",
        "\n",
        "    for i, (low, high) in enumerate(fms_ranges):\n",
        "        mask = (all_targets >= low) & (all_targets < high) if high < 10 else (all_targets >= low) & (all_targets <= high)\n",
        "        if np.any(mask):\n",
        "            range_residuals = np.abs(residuals[mask])\n",
        "            range_errors.append(range_residuals)\n",
        "            range_labels.append(f'{low}-{high}')\n",
        "\n",
        "    if range_errors:\n",
        "        box_plot = plt.boxplot(range_errors, labels=range_labels, patch_artist=True)\n",
        "        for patch, color in zip(box_plot['boxes'], range_colors[:len(range_errors)]):\n",
        "            patch.set_facecolor(color)\n",
        "            patch.set_alpha(0.7)\n",
        "\n",
        "        plt.xlabel('FMS Score Range', fontsize=12)\n",
        "        plt.ylabel('Absolute Error', fontsize=12)\n",
        "        plt.title('Error Distribution by FMS Range', fontsize=14, fontweight='bold')\n",
        "        plt.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "    # 8. Performance Metrics Comparison\n",
        "    ax8 = plt.subplot(4, 4, 8)\n",
        "    key_metrics = ['RMSE', 'MAE', 'R²', 'Lin_CCC', 'Clinical_Accuracy']\n",
        "    metric_values = [cv_metrics[f'{metric}_mean'] for metric in key_metrics]\n",
        "    metric_stds = [cv_metrics[f'{metric}_std'] for metric in key_metrics]\n",
        "\n",
        "    # Normalize metrics to 0-1 scale for comparison\n",
        "    normalized_values = []\n",
        "    for i, (metric, value) in enumerate(zip(key_metrics, metric_values)):\n",
        "        if metric in ['RMSE', 'MAE']:\n",
        "            # Lower is better - invert and normalize\n",
        "            norm_val = max(0, 1 - (value / 3.0))  # Assuming max reasonable error is 3\n",
        "        else:\n",
        "            # Higher is better - use as is (assuming already 0-1 scale)\n",
        "            norm_val = value\n",
        "        normalized_values.append(norm_val)\n",
        "\n",
        "    colors = ['#ff7f7f', '#7f7fff', '#7fff7f', '#ffff7f', '#ff7fff']\n",
        "    bars = plt.bar(key_metrics, normalized_values, color=colors, alpha=0.8, edgecolor='black', linewidth=1)\n",
        "\n",
        "    plt.ylabel('Normalized Performance', fontsize=12)\n",
        "    plt.title('Key Performance Metrics', fontsize=14, fontweight='bold')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.ylim(0, 1)\n",
        "    plt.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "    # Add original values as text\n",
        "    for bar, orig_val, std_val in zip(bars, metric_values, metric_stds):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
        "                f'{orig_val:.3f}±{std_val:.3f}', ha='center', va='bottom', fontsize=8, rotation=90)\n",
        "\n",
        "    # 9. Training Progress\n",
        "    ax9 = plt.subplot(4, 4, 9)\n",
        "    if all_train_losses and all_val_rmses:\n",
        "        # Align lengths\n",
        "        min_length = min(len(fold_result['train_losses']) for fold_result in fold_results if fold_result['train_losses'])\n",
        "        if min_length > 0:\n",
        "            train_losses_aligned = [fold_result['train_losses'][:min_length] for fold_result in fold_results if fold_result['train_losses']]\n",
        "            val_rmses_aligned = [fold_result['val_rmses'][:min_length] for fold_result in fold_results if fold_result['val_rmses']]\n",
        "\n",
        "            if train_losses_aligned and val_rmses_aligned:\n",
        "                avg_train_loss = np.mean(train_losses_aligned, axis=0)\n",
        "                avg_val_rmse = np.mean(val_rmses_aligned, axis=0)\n",
        "                std_train_loss = np.std(train_losses_aligned, axis=0)\n",
        "                std_val_rmse = np.std(val_rmses_aligned, axis=0)\n",
        "\n",
        "                epochs = range(1, len(avg_train_loss) + 1)\n",
        "\n",
        "                ax9_twin = ax9.twinx()\n",
        "\n",
        "                # Training loss\n",
        "                line1 = ax9.plot(epochs, avg_train_loss, 'b-', linewidth=2, label='Training Loss')\n",
        "                ax9.fill_between(epochs, avg_train_loss - std_train_loss, avg_train_loss + std_train_loss,\n",
        "                               alpha=0.2, color='blue')\n",
        "\n",
        "                # Validation RMSE\n",
        "                line2 = ax9_twin.plot(epochs, avg_val_rmse, 'r-', linewidth=2, label='Validation RMSE')\n",
        "                ax9_twin.fill_between(epochs, avg_val_rmse - std_val_rmse, avg_val_rmse + std_val_rmse,\n",
        "                                    alpha=0.2, color='red')\n",
        "\n",
        "                ax9.set_xlabel('Epoch', fontsize=12)\n",
        "                ax9.set_ylabel('Training Loss', color='b', fontsize=12)\n",
        "                ax9_twin.set_ylabel('Validation RMSE', color='r', fontsize=12)\n",
        "                ax9.set_title('Training Progress', fontsize=14, fontweight='bold')\n",
        "\n",
        "                # Combined legend\n",
        "                lines = line1 + line2\n",
        "                labels = [l.get_label() for l in lines]\n",
        "                ax9.legend(lines, labels, loc='upper right')\n",
        "                ax9.grid(True, alpha=0.3)\n",
        "\n",
        "    # 10. Distribution Comparison\n",
        "    ax10 = plt.subplot(4, 4, 10)\n",
        "    plt.hist(all_targets, bins=30, alpha=0.7, label='True FMS', color='skyblue', edgecolor='black', density=True)\n",
        "    plt.hist(all_predictions, bins=30, alpha=0.7, label='Predicted FMS', color='salmon', edgecolor='black', density=True)\n",
        "    plt.xlabel('FMS Scores', fontsize=12)\n",
        "    plt.ylabel('Density', fontsize=12)\n",
        "    plt.title('Distribution Comparison', fontsize=14, fontweight='bold')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # 11-16. Additional plots...\n",
        "    # (continuing with remaining subplots)\n",
        "\n",
        "    plt.tight_layout(pad=3.0)\n",
        "    plt.show()\n",
        "\n",
        "    # Print comprehensive analysis\n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "    print(\"COMPREHENSIVE ACADEMIC PERFORMANCE ANALYSIS\")\n",
        "    print(\"=\"*100)\n",
        "\n",
        "    print(f\"\\nPRIMARY REGRESSION METRICS:\")\n",
        "    print(f\"  Root Mean Square Error (RMSE):     {cv_metrics['RMSE_mean']:.4f} ± {cv_metrics['RMSE_std']:.4f}\")\n",
        "    print(f\"  Mean Absolute Error (MAE):         {cv_metrics['MAE_mean']:.4f} ± {cv_metrics['MAE_std']:.4f}\")\n",
        "    print(f\"  Coefficient of Determination (R²): {cv_metrics['R²_mean']:.4f} ± {cv_metrics['R²_std']:.4f}\")\n",
        "    print(f\"  Normalized MSE (NMSE):             {cv_metrics['NMSE_mean']:.4f} ± {cv_metrics['NMSE_std']:.4f}\")\n",
        "    print(f\"  Normalized MAE (NMAE):             {cv_metrics['NMAE_mean']:.4f} ± {cv_metrics['NMAE_std']:.4f}\")\n",
        "\n",
        "    print(f\"\\nPERCENTAGE ERROR METRICS:\")\n",
        "    print(f\"  Mean Absolute Percentage Error (MAPE):      {cv_metrics['MAPE_mean']:.2f}% ± {cv_metrics['MAPE_std']:.2f}%\")\n",
        "    print(f\"  Symmetric Mean Absolute Percentage Error:   {cv_metrics['SMAPE_mean']:.2f}% ± {cv_metrics['SMAPE_std']:.2f}%\")\n",
        "\n",
        "    print(f\"\\nCLINICAL ACCURACY METRICS:\")\n",
        "    print(f\"  Accuracy within ±0.25 FMS points:  {cv_metrics['Acc@0.25_mean']:.4f} ± {cv_metrics['Acc@0.25_std']:.4f} ({cv_metrics['Acc@0.25_mean']*100:.1f}%)\")\n",
        "    print(f\"  Accuracy within ±0.5  FMS points:  {cv_metrics['Acc@0.5_mean']:.4f} ± {cv_metrics['Acc@0.5_std']:.4f} ({cv_metrics['Acc@0.5_mean']*100:.1f}%)\")\n",
        "    print(f\"  Accuracy within ±1.0  FMS points:  {cv_metrics['Acc@1.0_mean']:.4f} ± {cv_metrics['Acc@1.0_std']:.4f} ({cv_metrics['Acc@1.0_mean']*100:.1f}%)\")\n",
        "    print(f\"  Accuracy within ±1.5  FMS points:  {cv_metrics['Acc@1.5_mean']:.4f} ± {cv_metrics['Acc@1.5_std']:.4f} ({cv_metrics['Acc@1.5_mean']*100:.1f}%)\")\n",
        "    print(f\"  Accuracy within ±2.0  FMS points:  {cv_metrics['Acc@2.0_mean']:.4f} ± {cv_metrics['Acc@2.0_std']:.4f} ({cv_metrics['Acc@2.0_mean']*100:.1f}%)\")\n",
        "\n",
        "    print(f\"\\nFUNCTIONAL CLASS METRICS:\")\n",
        "    print(f\"  Clinical Accuracy (exact class):    {cv_metrics['Clinical_Accuracy_mean']:.4f} ± {cv_metrics['Clinical_Accuracy_std']:.4f} ({cv_metrics['Clinical_Accuracy_mean']*100:.1f}%)\")\n",
        "    print(f\"  Adjacent Class Accuracy (±1 class): {cv_metrics['Adjacent_Class_Acc_mean']:.4f} ± {cv_metrics['Adjacent_Class_Acc_std']:.4f} ({cv_metrics['Adjacent_Class_Acc_mean']*100:.1f}%)\")\n",
        "\n",
        "    print(f\"\\nSTATISTICAL MEASURES:\")\n",
        "    print(f\"  Pearson Correlation (r):           {cv_metrics['Pearson_r_mean']:.4f} ± {cv_metrics['Pearson_r_std']:.4f}\")\n",
        "    print(f\"  Spearman Correlation (ρ):          {cv_metrics['Spearman_ρ_mean']:.4f} ± {cv_metrics['Spearman_ρ_std']:.4f}\")\n",
        "    print(f\"  Lin's Concordance Correlation:     {cv_metrics['Lin_CCC_mean']:.4f} ± {cv_metrics['Lin_CCC_std']:.4f}\")\n",
        "    print(f\"  Index of Agreement:                {cv_metrics['Index_Agreement_mean']:.4f} ± {cv_metrics['Index_Agreement_std']:.4f}\")\n",
        "\n",
        "    # Clinical interpretation\n",
        "    print(f\"\\nCLINICAL INTERPRETATION:\")\n",
        "    rmse_mean = cv_metrics['RMSE_mean']\n",
        "    acc_1_0 = cv_metrics['Acc@1.0_mean']\n",
        "    lin_ccc = cv_metrics['Lin_CCC_mean']\n",
        "    clinical_acc = cv_metrics['Clinical_Accuracy_mean']\n",
        "\n",
        "    if rmse_mean < 0.8:\n",
        "        rmse_interp = \"Excellent precision - RMSE < 0.8 FMS points\"\n",
        "    elif rmse_mean < 1.2:\n",
        "        rmse_interp = \"Very good precision - RMSE < 1.2 FMS points\"\n",
        "    elif rmse_mean < 1.5:\n",
        "        rmse_interp = \"Good precision - RMSE < 1.5 FMS points\"\n",
        "    elif rmse_mean < 2.0:\n",
        "        rmse_interp = \"Moderate precision - RMSE < 2.0 FMS points\"\n",
        "    else:\n",
        "        rmse_interp = \"Poor precision - RMSE > 2.0 FMS points\"\n",
        "\n",
        "    if lin_ccc > 0.90:\n",
        "        ccc_interp = \"Excellent agreement (CCC > 0.90)\"\n",
        "    elif lin_ccc > 0.80:\n",
        "        ccc_interp = \"Good agreement (CCC > 0.80)\"\n",
        "    elif lin_ccc > 0.65:\n",
        "        ccc_interp = \"Moderate agreement (CCC > 0.65)\"\n",
        "    else:\n",
        "        ccc_interp = \"Poor agreement (CCC < 0.65)\"\n",
        "\n",
        "    print(f\"  • {rmse_interp}\")\n",
        "    print(f\"  • {ccc_interp}\")\n",
        "    print(f\"  • Clinical utility: {clinical_acc*100:.1f}% correct functional classification\")\n",
        "    print(f\"  • Practical accuracy: {acc_1_0*100:.1f}% predictions within 1 FMS point\")\n",
        "\n",
        "    print(f\"\\nRECOMMENDATIONS FOR ACADEMIC REPORTING:\")\n",
        "    print(f\"  1. Primary metric: RMSE = {cv_metrics['RMSE_mean']:.3f} ± {cv_metrics['RMSE_std']:.3f}\")\n",
        "    print(f\"  2. Agreement measure: Lin's CCC = {cv_metrics['Lin_CCC_mean']:.3f} ± {cv_metrics['Lin_CCC_std']:.3f}\")\n",
        "    print(f\"  3. Clinical relevance: {acc_1_0*100:.1f}% within ±1.0 FMS point\")\n",
        "    print(f\"  4. Functional classification: {clinical_acc*100:.1f}% correct class assignment\")\n",
        "    print(f\"  5. Bias analysis: Mean bias = {cv_metrics['Bias_mean']:.3f} (systematic error)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPbnPmv5HJ-D"
      },
      "outputs": [],
      "source": [
        "def generate_academic_report(results: Dict, output_file: str = \"fms_regression_report.txt\"):\n",
        "    \"\"\"Generate a comprehensive academic report\"\"\"\n",
        "\n",
        "    if results is None:\n",
        "        print(\"No results to report\")\n",
        "        return\n",
        "\n",
        "    cv_metrics = results['cv_metrics']\n",
        "    fold_results = results['fold_results']\n",
        "\n",
        "    report = []\n",
        "    report.append(\"=\" * 80)\n",
        "    report.append(\"FUNCTIONAL MOVEMENT SCREEN (FMS) PREDICTION MODEL\")\n",
        "    report.append(\"COMPREHENSIVE ACADEMIC PERFORMANCE REPORT\")\n",
        "    report.append(\"=\" * 80)\n",
        "    report.append(\"\")\n",
        "\n",
        "    report.append(\"ABSTRACT\")\n",
        "    report.append(\"-\" * 40)\n",
        "    report.append(f\"This study presents an enhanced ordinal regression model for predicting Functional Movement Screen (FMS) scores\")\n",
        "    report.append(f\"using virtual reality sensor data. The model achieved an RMSE of {cv_metrics['RMSE_mean']:.3f} ± {cv_metrics['RMSE_std']:.3f}\")\n",
        "    report.append(f\"with {cv_metrics['Acc@1.0_mean']*100:.1f}% of predictions within ±1.0 FMS points of true values.\")\n",
        "    report.append(f\"Lin's concordance correlation coefficient was {cv_metrics['Lin_CCC_mean']:.3f} ± {cv_metrics['Lin_CCC_std']:.3f},\")\n",
        "    report.append(f\"indicating {'excellent' if cv_metrics['Lin_CCC_mean'] > 0.9 else 'good' if cv_metrics['Lin_CCC_mean'] > 0.8 else 'moderate'} agreement between predicted and true scores.\")\n",
        "    report.append(\"\")\n",
        "\n",
        "    report.append(\"METHODOLOGY\")\n",
        "    report.append(\"-\" * 40)\n",
        "    report.append(f\"• Model Architecture: Enhanced Ordinal Regression with Attention Mechanism\")\n",
        "    report.append(f\"• Cross-Validation: {len(fold_results)}-fold GroupKFold (participant-based splitting)\")\n",
        "    report.append(f\"• Oversampling Method: {results.get('oversampling_method', 'Not specified')}\")\n",
        "    report.append(f\"• Sample Size: Improved through advanced oversampling techniques\")\n",
        "    report.append(f\"• Evaluation: Comprehensive metrics including clinical relevance measures\")\n",
        "    report.append(\"\")\n",
        "\n",
        "    report.append(\"RESULTS\")\n",
        "    report.append(\"-\" * 40)\n",
        "    report.append(\"\")\n",
        "    report.append(\"Primary Performance Metrics:\")\n",
        "    report.append(f\"  Root Mean Square Error (RMSE):     {cv_metrics['RMSE_mean']:.4f} ± {cv_metrics['RMSE_std']:.4f}\")\n",
        "    report.append(f\"  Mean Absolute Error (MAE):         {cv_metrics['MAE_mean']:.4f} ± {cv_metrics['MAE_std']:.4f}\")\n",
        "    report.append(f\"  Coefficient of Determination (R²): {cv_metrics['R²_mean']:.4f} ± {cv_metrics['R²_std']:.4f}\")\n",
        "    report.append(\"\")\n",
        "\n",
        "    report.append(\"Agreement and Correlation Measures:\")\n",
        "    report.append(f\"  Lin's Concordance Correlation:     {cv_metrics['Lin_CCC_mean']:.4f} ± {cv_metrics['Lin_CCC_std']:.4f}\")\n",
        "    report.append(f\"  Pearson Correlation:               {cv_metrics['Pearson_r_mean']:.4f} ± {cv_metrics['Pearson_r_std']:.4f}\")\n",
        "    report.append(f\"  Index of Agreement:                {cv_metrics['Index_Agreement_mean']:.4f} ± {cv_metrics['Index_Agreement_std']:.4f}\")\n",
        "    report.append(\"\")\n",
        "\n",
        "    report.append(\"Clinical Relevance:\")\n",
        "    report.append(f\"  Accuracy within ±0.5 FMS points:  {cv_metrics['Acc@0.5_mean']:.4f} ({cv_metrics['Acc@0.5_mean']*100:.1f}%)\")\n",
        "    report.append(f\"  Accuracy within ±1.0 FMS points:  {cv_metrics['Acc@1.0_mean']:.4f} ({cv_metrics['Acc@1.0_mean']*100:.1f}%)\")\n",
        "    report.append(f\"  Accuracy within ±1.5 FMS points:  {cv_metrics['Acc@1.5_mean']:.4f} ({cv_metrics['Acc@1.5_mean']*100:.1f}%)\")\n",
        "    report.append(f\"  Functional Class Accuracy:        {cv_metrics['Clinical_Accuracy_mean']:.4f} ({cv_metrics['Clinical_Accuracy_mean']*100:.1f}%)\")\n",
        "    report.append(\"\")\n",
        "\n",
        "    report.append(\"Bias and Precision Analysis:\")\n",
        "    report.append(f\"  Mean Bias:                         {cv_metrics['Bias_mean']:.4f} ± {cv_metrics['Bias_std']:.4f}\")\n",
        "    report.append(f\"  95% Limits of Agreement:           [{cv_metrics['LoA_Lower_mean']:.3f}, {cv_metrics['LoA_Upper_mean']:.3f}]\")\n",
        "    report.append(\"\")\n",
        "\n",
        "    report.append(\"STATISTICAL SIGNIFICANCE\")\n",
        "    report.append(\"-\" * 40)\n",
        "    # Calculate confidence intervals\n",
        "    n_folds = len(fold_results)\n",
        "    rmse_values = [fold['metrics']['RMSE'] for fold in fold_results]\n",
        "    rmse_ci_lower = np.percentile(rmse_values, 2.5)\n",
        "    rmse_ci_upper = np.percentile(rmse_values, 97.5)\n",
        "\n",
        "    report.append(f\"95% Confidence Intervals (n={n_folds} folds):\")\n",
        "    report.append(f\"  RMSE: [{rmse_ci_lower:.4f}, {rmse_ci_upper:.4f}]\")\n",
        "\n",
        "    mae_values = [fold['metrics']['MAE'] for fold in fold_results]\n",
        "    mae_ci_lower = np.percentile(mae_values, 2.5)\n",
        "    mae_ci_upper = np.percentile(mae_values, 97.5)\n",
        "    report.append(f\"  MAE:  [{mae_ci_lower:.4f}, {mae_ci_upper:.4f}]\")\n",
        "    report.append(\"\")\n",
        "\n",
        "    report.append(\"MODEL IMPROVEMENTS\")\n",
        "    report.append(\"-\" * 40)\n",
        "    report.append(\"• Advanced oversampling techniques to address class imbalance\")\n",
        "    report.append(\"• Focal loss implementation to handle minority classes\")\n",
        "    report.append(\"• Enhanced feature engineering with contextual information\")\n",
        "    report.append(\"• Comprehensive evaluation with clinical relevance metrics\")\n",
        "    report.append(\"• Robust cross-validation with participant-based splitting\")\n",
        "    report.append(\"\")\n",
        "\n",
        "    report.append(\"CLINICAL INTERPRETATION\")\n",
        "    report.append(\"-\" * 40)\n",
        "    rmse_mean = cv_metrics['RMSE_mean']\n",
        "    if rmse_mean < 1.0:\n",
        "        interpretation = \"Excellent clinical utility - predictions are highly accurate\"\n",
        "    elif rmse_mean < 1.5:\n",
        "        interpretation = \"Good clinical utility - suitable for screening and monitoring\"\n",
        "    elif rmse_mean < 2.0:\n",
        "        interpretation = \"Moderate clinical utility - useful as supportive assessment tool\"\n",
        "    else:\n",
        "        interpretation = \"Limited clinical utility - requires further improvement\"\n",
        "\n",
        "    report.append(f\"Model Performance: {interpretation}\")\n",
        "    report.append(f\"Practical Impact: {cv_metrics['Acc@1.0_mean']*100:.1f}% of predictions within clinically acceptable range (±1.0 FMS point)\")\n",
        "    report.append(\"\")\n",
        "\n",
        "    report.append(\"RECOMMENDED CITATION FORMAT\")\n",
        "    report.append(\"-\" * 40)\n",
        "    report.append(\"The enhanced ordinal regression model demonstrated strong predictive performance\")\n",
        "    report.append(f\"(RMSE = {cv_metrics['RMSE_mean']:.3f}, 95% CI [{rmse_ci_lower:.3f}, {rmse_ci_upper:.3f}]; \")\n",
        "    report.append(f\"Lin's CCC = {cv_metrics['Lin_CCC_mean']:.3f} ± {cv_metrics['Lin_CCC_std']:.3f}) with \")\n",
        "    report.append(f\"{cv_metrics['Acc@1.0_mean']*100:.1f}% of predictions within ±1.0 FMS point of true scores.\")\n",
        "    report.append(\"\")\n",
        "\n",
        "    report.append(\"=\" * 80)\n",
        "\n",
        "    # Write to file\n",
        "    with open(output_file, 'w') as f:\n",
        "        f.write('\\n'.join(report))\n",
        "\n",
        "    print(f\"Academic report generated: {output_file}\")\n",
        "    return '\\n'.join(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qp8k40vtHNRE"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    \"\"\"\n",
        "    Main execution function for Enhanced FMS Regression with Advanced Oversampling\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(\"ENHANCED FMS REGRESSION WITH ADVANCED OVERSAMPLING\")\n",
        "    print(\"Enhanced Ordinal Regression for Functional Movement Screen Prediction\")\n",
        "    print(\"=\" * 80)\n",
        "    print()\n",
        "\n",
        "    # Configuration Parameters\n",
        "    print(\"PIPELINE CONFIGURATION:\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    # File paths - Update these to your actual file paths\n",
        "    vrnet_csv_path = \"/content/drive/MyDrive/[anon]/vrnet_preprocessed_1hz_complete.csv\"\n",
        "    vrwalking_csv_path = \"/content/drive/MyDrive/[anon]/final_data.csv\"\n",
        "\n",
        "    # Model parameters\n",
        "    config = {\n",
        "        'window_size': 60,                    # Time window size for sequence extraction\n",
        "        'n_folds': 10,                       # Number of cross-validation folds\n",
        "        'num_epochs': 100,                   # Maximum training epochs\n",
        "        'tune_hyperparams': True,            # Enable hyperparameter tuning\n",
        "        'oversampling_method': 'smote_tomek' # Oversampling technique\n",
        "    }\n",
        "\n",
        "    # Available oversampling methods\n",
        "    oversampling_options = [\n",
        "        'smote',            # SMOTE (Synthetic Minority Oversampling Technique)\n",
        "        'adasyn',           # ADASYN (Adaptive Synthetic Sampling)\n",
        "        'borderline_smote', # BorderlineSMOTE (focuses on borderline cases)\n",
        "        'smote_enn',        # SMOTEENN (SMOTE + Edited Nearest Neighbors)\n",
        "        'smote_tomek'       # SMOTE-Tomek (SMOTE + Tomek links removal)\n",
        "    ]\n",
        "\n",
        "    print(f\"  Data Sources:\")\n",
        "    print(f\"    VR.net data: {vrnet_csv_path}\")\n",
        "    print(f\"    VRWalking data: {vrwalking_csv_path}\")\n",
        "    print(f\"  Model Configuration:\")\n",
        "    print(f\"    Window size: {config['window_size']} frames\")\n",
        "    print(f\"    Cross-validation folds: {config['n_folds']}\")\n",
        "    print(f\"    Maximum epochs: {config['num_epochs']}\")\n",
        "    print(f\"    Hyperparameter tuning: {config['tune_hyperparams']}\")\n",
        "    print(f\"    Oversampling method: {config['oversampling_method']}\")\n",
        "    print(f\"  Available oversampling options: {', '.join(oversampling_options)}\")\n",
        "    print()\n",
        "\n",
        "    # Validate file paths\n",
        "    import os\n",
        "    if not os.path.exists(vrnet_csv_path):\n",
        "        print(f\"Warning: VR.net data file not found: {vrnet_csv_path}\")\n",
        "        print(\"Please update the vrnet_csv_path variable with the correct path\")\n",
        "        return None\n",
        "\n",
        "    if not os.path.exists(vrwalking_csv_path):\n",
        "        print(f\"Warning: VRWalking data file not found: {vrwalking_csv_path}\")\n",
        "        print(\"Please update the vrwalking_csv_path variable with the correct path\")\n",
        "        return None\n",
        "\n",
        "    print(\"STARTING ENHANCED PIPELINE...\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    try:\n",
        "        # Execute the enhanced pipeline\n",
        "        results = run_enhanced_pipeline(\n",
        "            vrnet_csv_path=vrnet_csv_path,\n",
        "            vrwalking_csv_path=vrwalking_csv_path,\n",
        "            window_size=config['window_size'],\n",
        "            n_folds=config['n_folds'],\n",
        "            num_epochs=config['num_epochs'],\n",
        "            tune_hyperparams=config['tune_hyperparams'],\n",
        "            oversampling_method=config['oversampling_method']\n",
        "        )\n",
        "\n",
        "        if results is not None:\n",
        "            print(\"\\n\" + \"=\" * 80)\n",
        "            print(\"PIPELINE EXECUTION SUCCESSFUL!\")\n",
        "            print(\"=\" * 80)\n",
        "\n",
        "            # Generate comprehensive academic report\n",
        "            print(\"\\nGenerating academic report...\")\n",
        "            report_text = generate_academic_report(results, \"fms_regression_academic_report.txt\")\n",
        "\n",
        "            # Extract key results\n",
        "            cv_metrics = results['cv_metrics']\n",
        "            best_params = results['best_hyperparams']\n",
        "\n",
        "            print(\"\\nKEY RESULTS SUMMARY:\")\n",
        "            print(\"-\" * 30)\n",
        "            print(f\"Model Performance:\")\n",
        "            print(f\"  RMSE: {cv_metrics['RMSE_mean']:.4f} ± {cv_metrics['RMSE_std']:.4f}\")\n",
        "            print(f\"  MAE:  {cv_metrics['MAE_mean']:.4f} ± {cv_metrics['MAE_std']:.4f}\")\n",
        "            print(f\"  R²:   {cv_metrics['R²_mean']:.4f} ± {cv_metrics['R²_std']:.4f}\")\n",
        "\n",
        "            print(f\"\\nAgreement Measures:\")\n",
        "            print(f\"  Lin's CCC: {cv_metrics['Lin_CCC_mean']:.4f} ± {cv_metrics['Lin_CCC_std']:.4f}\")\n",
        "            print(f\"  Pearson r: {cv_metrics['Pearson_r_mean']:.4f} ± {cv_metrics['Pearson_r_std']:.4f}\")\n",
        "\n",
        "            print(f\"\\nClinical Relevance:\")\n",
        "            print(f\"  Accuracy ±1.0 FMS: {cv_metrics['Acc@1.0_mean']*100:.1f}% ± {cv_metrics['Acc@1.0_std']*100:.1f}%\")\n",
        "            print(f\"  Functional Class:  {cv_metrics['Clinical_Accuracy_mean']*100:.1f}% ± {cv_metrics['Clinical_Accuracy_std']*100:.1f}%\")\n",
        "            print(f\"  Mean Bias: {cv_metrics['Bias_mean']:.4f} ± {cv_metrics['Bias_std']:.4f}\")\n",
        "\n",
        "            print(f\"\\nOptimal Hyperparameters:\")\n",
        "            for param, value in best_params.items():\n",
        "                if isinstance(value, float):\n",
        "                    print(f\"  {param}: {value:.4f}\")\n",
        "                else:\n",
        "                    print(f\"  {param}: {value}\")\n",
        "\n",
        "            # Performance interpretation\n",
        "            print(f\"\\nCLINICAL INTERPRETATION:\")\n",
        "            rmse_mean = cv_metrics['RMSE_mean']\n",
        "            acc_1_0 = cv_metrics['Acc@1.0_mean']\n",
        "            lin_ccc = cv_metrics['Lin_CCC_mean']\n",
        "\n",
        "            if rmse_mean < 1.0:\n",
        "                performance_level = \"Excellent\"\n",
        "                clinical_utility = \"High - suitable for clinical screening and monitoring\"\n",
        "            elif rmse_mean < 1.5:\n",
        "                performance_level = \"Good\"\n",
        "                clinical_utility = \"Moderate - useful for supportive assessment\"\n",
        "            elif rmse_mean < 2.0:\n",
        "                performance_level = \"Fair\"\n",
        "                clinical_utility = \"Limited - requires clinical expertise interpretation\"\n",
        "            else:\n",
        "                performance_level = \"Poor\"\n",
        "                clinical_utility = \"Insufficient for clinical use\"\n",
        "\n",
        "            print(f\"  Performance Level: {performance_level} (RMSE = {rmse_mean:.3f})\")\n",
        "            print(f\"  Clinical Utility: {clinical_utility}\")\n",
        "            print(f\"  Agreement Quality: {'Excellent' if lin_ccc > 0.9 else 'Good' if lin_ccc > 0.8 else 'Moderate' if lin_ccc > 0.65 else 'Poor'} (CCC = {lin_ccc:.3f})\")\n",
        "\n",
        "            print(f\"\\nOUTPUT FILES:\")\n",
        "            print(f\"  Academic report: fms_regression_academic_report.txt\")\n",
        "            print(f\"  Model visualizations: Displayed above\")\n",
        "\n",
        "            return results\n",
        "\n",
        "        else:\n",
        "            print(\"\\n\" + \"=\" * 80)\n",
        "            print(\"PIPELINE EXECUTION FAILED!\")\n",
        "            print(\"=\" * 80)\n",
        "            print(\"Please check the error messages above and verify:\")\n",
        "            print(\"1. File paths are correct and files exist\")\n",
        "            print(\"2. Required packages are installed (imblearn, optuna, etc.)\")\n",
        "            print(\"3. Sufficient memory is available for processing\")\n",
        "            print(\"4. Input data format matches expected structure\")\n",
        "            return None\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nCRITICAL ERROR: {str(e)}\")\n",
        "        print(\"\\nTROUBLESHOOTING:\")\n",
        "        print(\"1. Verify all required packages are installed:\")\n",
        "        print(\"   pip install imbalanced-learn optuna scikit-learn torch\")\n",
        "        print(\"2. Check file paths and data format\")\n",
        "        print(\"3. Ensure sufficient system memory\")\n",
        "        print(\"4. Review the full error traceback above\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHlCkslEHPkU"
      },
      "outputs": [],
      "source": [
        "def usage_examples():\n",
        "    \"\"\"\n",
        "    Demonstrate different usage patterns for the enhanced FMS regression pipeline\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"USAGE EXAMPLES:\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    print(\"\\n1. BASIC USAGE (with default parameters):\")\n",
        "    print(\"\"\"\n",
        "    results = run_enhanced_pipeline(\n",
        "        vrnet_csv_path=\"path/to/vrnet_data.csv\",\n",
        "        vrwalking_csv_path=\"path/to/vrwalking_data.csv\"\n",
        "    )\n",
        "    \"\"\")\n",
        "\n",
        "    print(\"\\n2. QUICK EVALUATION (reduced epochs, no hyperparameter tuning):\")\n",
        "    print(\"\"\"\n",
        "    results = run_enhanced_pipeline(\n",
        "        vrnet_csv_path=\"path/to/vrnet_data.csv\",\n",
        "        vrwalking_csv_path=\"path/to/vrwalking_data.csv\",\n",
        "        num_epochs=50,\n",
        "        n_folds=5,\n",
        "        tune_hyperparams=False\n",
        "    )\n",
        "    \"\"\")\n",
        "\n",
        "    print(\"\\n3. DIFFERENT OVERSAMPLING METHODS:\")\n",
        "    for method in ['smote', 'adasyn', 'borderline_smote', 'smote_enn', 'smote_tomek']:\n",
        "        print(f\"\"\"\n",
        "    # Using {method}:\n",
        "    results = run_enhanced_pipeline(\n",
        "        vrnet_csv_path=\"path/to/vrnet_data.csv\",\n",
        "        vrwalking_csv_path=\"path/to/vrwalking_data.csv\",\n",
        "        oversampling_method='{method}'\n",
        "    )\n",
        "        \"\"\")\n",
        "\n",
        "    print(\"\\n4. CUSTOM WINDOW SIZE AND COMPREHENSIVE EVALUATION:\")\n",
        "    print(\"\"\"\n",
        "    results = run_enhanced_pipeline(\n",
        "        vrnet_csv_path=\"path/to/vrnet_data.csv\",\n",
        "        vrwalking_csv_path=\"path/to/vrwalking_data.csv\",\n",
        "        window_size=120,  # Longer sequences\n",
        "        n_folds=15,       # More rigorous CV\n",
        "        num_epochs=150,   # More training\n",
        "        tune_hyperparams=True\n",
        "    )\n",
        "    \"\"\")\n",
        "\n",
        "    print(\"\\n5. GENERATE ACADEMIC REPORT FROM RESULTS:\")\n",
        "    print(\"\"\"\n",
        "    if results is not None:\n",
        "        report = generate_academic_report(results, \"custom_report.txt\")\n",
        "        print(\"Report saved to custom_report.txt\")\n",
        "    \"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcZ__dIqzf9k"
      },
      "outputs": [],
      "source": [
        "def extract_running_example_after_training(X, y, participant_ids, datasets, fold_results, target_fms=7.2):\n",
        "    \"\"\"\n",
        "    Extract running example using a trained model from the CV folds\n",
        "\n",
        "    Args:\n",
        "        X: Processed feature matrix from pipeline\n",
        "        y: Target FMS scores from pipeline\n",
        "        participant_ids: Participant IDs from pipeline\n",
        "        datasets: Dataset names from pipeline\n",
        "        fold_results: Results from cross-validation training\n",
        "        target_fms: Target FMS score for example (default: 7.2)\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with all intermediate values for the running example\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"EXTRACTING RUNNING EXAMPLE AFTER MODEL TRAINING\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Use the first fold's trained model\n",
        "    best_model = fold_results[0]['model']  # Trained model from first fold\n",
        "    best_model.eval()\n",
        "\n",
        "    print(f\"Using trained model from fold 1\")\n",
        "    print(f\"Data shape: X={X.shape}, y={y.shape}\")\n",
        "\n",
        "    # Find a real sample (not synthetic) close to target FMS\n",
        "    real_mask = [not pid.startswith('synthetic_') for pid in participant_ids]\n",
        "    real_indices = [i for i, is_real in enumerate(real_mask) if is_real]\n",
        "\n",
        "    # Find sample closest to target FMS\n",
        "    best_idx = None\n",
        "    best_diff = float('inf')\n",
        "\n",
        "    for idx in real_indices:\n",
        "        diff = abs(y[idx] - target_fms)\n",
        "        if diff < best_diff:\n",
        "            best_diff = diff\n",
        "            best_idx = idx\n",
        "\n",
        "    if best_idx is None:\n",
        "        best_idx = real_indices[0]  # Fallback to first real sample\n",
        "\n",
        "    selected_fms = y[best_idx]\n",
        "    selected_features = X[best_idx]\n",
        "    selected_participant = participant_ids[best_idx]\n",
        "    selected_dataset = datasets[best_idx]\n",
        "\n",
        "    print(f\"Selected sample: Participant {selected_participant} from {selected_dataset}\")\n",
        "    print(f\"FMS score: {selected_fms:.3f} (target: {target_fms})\")\n",
        "    print(f\"Features (first 10): {selected_features[:10]}\")\n",
        "\n",
        "    # Convert to tensor\n",
        "    sample_input = torch.tensor(selected_features, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "    print(\"\\n\" + \"-\"*80)\n",
        "    print(\"EXTRACTING ALL INTERMEDIATE VALUES FROM TRAINED MODEL\")\n",
        "    print(\"-\"*80)\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Get model predictions and intermediate values\n",
        "        expected_values, regression_output, class_probs = best_model.forward(sample_input)\n",
        "\n",
        "        # Original input\n",
        "        results['original_input'] = selected_features\n",
        "        print(f\"Input features (45D): {selected_features[:10]}... (showing first 10)\")\n",
        "\n",
        "        # Get intermediate values by forward pass through each component\n",
        "        x_norm = best_model.input_norm(sample_input)\n",
        "        results['normalized_input'] = x_norm.cpu().numpy().flatten()\n",
        "        print(f\"Normalized: {results['normalized_input'][:10]}... (showing first 10)\")\n",
        "\n",
        "        # Feature extraction through layers\n",
        "        features = x_norm\n",
        "        layer_results = []\n",
        "\n",
        "        for i, layer in enumerate(best_model.feature_layers):\n",
        "            if isinstance(layer, nn.Identity):\n",
        "                continue\n",
        "            prev_features = features\n",
        "            features = layer(features)\n",
        "\n",
        "            # Add residual connection if dimensions match\n",
        "            if prev_features.shape[-1] == features.shape[-1]:\n",
        "                features = features + prev_features\n",
        "\n",
        "            layer_results.append(features.cpu().numpy().flatten())\n",
        "            print(f\"Layer {i+1} ({features.shape[1]}D): {features.cpu().numpy().flatten()[:10]}...\")\n",
        "\n",
        "        results['layer_outputs'] = layer_results\n",
        "\n",
        "        # Attention mechanism\n",
        "        attn_input = features.unsqueeze(1)\n",
        "        attn_output, attn_weights = best_model.attention(attn_input, attn_input, attn_input)\n",
        "        h_attn = attn_output.squeeze(1) + features\n",
        "\n",
        "        results['attention_output'] = h_attn.cpu().numpy().flatten()\n",
        "        results['attention_weights'] = attn_weights.cpu().numpy()\n",
        "        print(f\"After attention ({h_attn.shape[1]}D): {h_attn.cpu().numpy().flatten()[:10]}...\")\n",
        "\n",
        "        # Ordinal regression head\n",
        "        ordinal_score = best_model.ordinal_projection(h_attn).squeeze(-1)\n",
        "        results['ordinal_score_s'] = ordinal_score.item()\n",
        "\n",
        "        sorted_thresholds = torch.sort(best_model.ordinal_thresholds)[0]\n",
        "        results['learned_thresholds'] = sorted_thresholds.cpu().numpy()\n",
        "\n",
        "        # Cumulative probabilities\n",
        "        cumulative_probs = torch.sigmoid(\n",
        "            sorted_thresholds.unsqueeze(0) - ordinal_score.unsqueeze(1)\n",
        "        )\n",
        "        results['cumulative_probabilities'] = cumulative_probs.cpu().numpy().flatten()\n",
        "\n",
        "        # Individual class probabilities (already computed from forward pass)\n",
        "        results['individual_class_probabilities'] = class_probs.cpu().numpy().flatten()\n",
        "\n",
        "        # Expected value (already computed from forward pass)\n",
        "        results['expected_value_ordinal'] = expected_values.item()\n",
        "\n",
        "        # Direct regression output (already computed from forward pass)\n",
        "        results['regression_output'] = regression_output.item()\n",
        "\n",
        "        # Final prediction using the optimized weights\n",
        "        combined = 0.606 * expected_values + 0.394 * regression_output  # Use your optimized weights\n",
        "        results['combined_prediction'] = combined.item()\n",
        "\n",
        "        # Loss calculations\n",
        "        target_tensor = torch.tensor([selected_fms])\n",
        "        target_class = torch.clamp(torch.round(target_tensor) - 1, 0, 9).long()\n",
        "\n",
        "        ordinal_loss = F.cross_entropy(torch.log(class_probs + 1e-7), target_class)\n",
        "        regression_loss = F.smooth_l1_loss(regression_output, target_tensor)\n",
        "        combined_loss = F.smooth_l1_loss(combined, target_tensor)\n",
        "        total_loss = 0.606 * ordinal_loss + 0.468 * regression_loss + 0.2 * combined_loss\n",
        "\n",
        "        results.update({\n",
        "            'target_fms': selected_fms,\n",
        "            'target_class': target_class.item(),\n",
        "            'ordinal_loss': ordinal_loss.item(),\n",
        "            'regression_loss': regression_loss.item(),\n",
        "            'combined_loss': combined_loss.item(),\n",
        "            'total_loss': total_loss.item(),\n",
        "            'participant_id': selected_participant,\n",
        "            'dataset': selected_dataset\n",
        "        })\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"RUNNING EXAMPLE SUMMARY\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"Participant: {selected_participant} from {selected_dataset}\")\n",
        "    print(f\"Ordinal score (s): {results['ordinal_score_s']:.4f}\")\n",
        "    print(f\"Learned thresholds: {results['learned_thresholds']}\")\n",
        "    print(f\"Most likely FMS class: {np.argmax(results['individual_class_probabilities']) + 1}\")\n",
        "    print(f\"Expected value: {results['expected_value_ordinal']:.4f}\")\n",
        "    print(f\"Regression output: {results['regression_output']:.4f}\")\n",
        "    print(f\"Final prediction: {results['combined_prediction']:.4f}\")\n",
        "    print(f\"Actual FMS: {selected_fms:.3f}\")\n",
        "    print(f\"Prediction error: {abs(results['combined_prediction'] - selected_fms):.4f}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"VALUES FOR PAPER EQUATIONS\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"s = {results['ordinal_score_s']:.4f}\")\n",
        "    print(f\"θ = {results['learned_thresholds']}\")\n",
        "    print(f\"Cumulative probs: {results['cumulative_probabilities']}\")\n",
        "    print(f\"Class probs: {results['individual_class_probabilities']}\")\n",
        "    print(f\"E[Y] = {results['expected_value_ordinal']:.4f}\")\n",
        "    print(f\"Regression = {results['regression_output']:.4f}\")\n",
        "    print(f\"Final = {results['combined_prediction']:.4f}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Usage: Add this at the end of your run_enhanced_pipeline function, after fold_results is populated:\n",
        "#\n",
        "# # Extract running example using trained model\n",
        "# running_example = extract_running_example_after_training(\n",
        "#     X=X,\n",
        "#     y=y,\n",
        "#     participant_ids=participant_ids,\n",
        "#     datasets=datasets,\n",
        "#     fold_results=fold_results,\n",
        "#     target_fms=7.2\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmwP0Ov5HniA"
      },
      "outputs": [],
      "source": [
        "def run_enhanced_pipeline(vrnet_csv_path: str, vrwalking_csv_path: str,\n",
        "                         window_size: int = 60, n_folds: int = 10,\n",
        "                         num_epochs: int = 100, tune_hyperparams: bool = True,\n",
        "                         oversampling_method: str = 'smote_tomek'):\n",
        "    \"\"\"Run the complete enhanced pipeline with advanced oversampling\"\"\"\n",
        "\n",
        "    print(\"STARTING ENHANCED ORDINAL REGRESSION PIPELINE WITH ADVANCED OVERSAMPLING\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    try:\n",
        "        # Load and clean data\n",
        "        print(\"Loading and cleaning data...\")\n",
        "        vrnet_df, vrwalking_df = load_and_clean_data(vrnet_csv_path, vrwalking_csv_path)\n",
        "\n",
        "        # Process with enhanced processor including oversampling\n",
        "        processor = EnhancedTimeSeriesProcessor(\n",
        "            window_size=window_size,\n",
        "            overlap=0.5,\n",
        "            oversampling_method=oversampling_method\n",
        "        )\n",
        "        X, y, participant_ids, datasets = processor.process_all_data(vrnet_df, vrwalking_df)\n",
        "\n",
        "        # Hyperparameter tuning\n",
        "        best_params = {}\n",
        "        if tune_hyperparams:\n",
        "            print(\"\\nHYPERPARAMETER TUNING WITH OVERSAMPLING\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "            tuner = HyperparameterTuner(X, y, participant_ids, datasets, n_folds=3)\n",
        "            best_params = tuner.tune(n_trials=30)\n",
        "        else:\n",
        "            # Default hyperparameters\n",
        "            best_params = {\n",
        "                'hidden_dims': [512, 256, 128, 64],\n",
        "                'dropout': 0.3,\n",
        "                'lr': 1e-3,\n",
        "                'batch_size': 64,\n",
        "                'ordinal_weight': 0.6,\n",
        "                'regression_weight': 0.4,\n",
        "                'focal_alpha': 0.25,\n",
        "                'focal_gamma': 2.0,\n",
        "                'weight_decay': 1e-4,\n",
        "                'oversampling_method': oversampling_method\n",
        "            }\n",
        "\n",
        "        # Cross-validation with enhanced model and oversampling\n",
        "        print(f\"\\nCROSS-VALIDATION WITH OVERSAMPLING ({n_folds} folds)\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        # Filter out synthetic participants for proper CV split\n",
        "        real_participant_mask = [not pid.startswith('synthetic_') for pid in participant_ids]\n",
        "        real_indices = [i for i, is_real in enumerate(real_participant_mask) if is_real]\n",
        "\n",
        "        if len(real_indices) < len(participant_ids):\n",
        "            print(f\"  Note: Using {len(real_indices)} real samples for CV split (excluding {len(participant_ids) - len(real_indices)} synthetic samples)\")\n",
        "\n",
        "        real_participant_ids = [participant_ids[i] for i in real_indices]\n",
        "        unique_participants = list(set(real_participant_ids))\n",
        "        participant_to_group = {pid: i for i, pid in enumerate(unique_participants)}\n",
        "\n",
        "        # Create groups for all samples (including synthetic)\n",
        "        groups = []\n",
        "        for pid in participant_ids:\n",
        "            if pid.startswith('synthetic_'):\n",
        "                # Assign synthetic samples to random groups\n",
        "                groups.append(np.random.randint(0, len(unique_participants)))\n",
        "            else:\n",
        "                groups.append(participant_to_group[pid])\n",
        "\n",
        "        kfold = GroupKFold(n_splits=n_folds)\n",
        "        # Use only real participant data for creating splits\n",
        "        X_real = X[real_indices]\n",
        "        y_real = y[real_indices]\n",
        "        groups_real = [groups[i] for i in real_indices]\n",
        "\n",
        "        splits = list(kfold.split(X_real, y_real, groups_real))\n",
        "\n",
        "        fold_results = []\n",
        "\n",
        "        for fold_idx, (train_indices_real, val_indices_real) in enumerate(splits):\n",
        "            print(f\"\\n--- FOLD {fold_idx + 1}/{n_folds} ---\")\n",
        "\n",
        "            # Map back to full dataset indices\n",
        "            train_indices = [real_indices[i] for i in train_indices_real]\n",
        "            val_indices = [real_indices[i] for i in val_indices_real]\n",
        "\n",
        "            # Add synthetic samples to training set only\n",
        "            synthetic_indices = [i for i, pid in enumerate(participant_ids) if pid.startswith('synthetic_')]\n",
        "            train_indices.extend(synthetic_indices)\n",
        "\n",
        "            # Split data\n",
        "            X_train, X_val = X[train_indices], X[val_indices]\n",
        "            y_train, y_val = y[train_indices], y[val_indices]\n",
        "            train_pids = [participant_ids[i] for i in train_indices]\n",
        "            val_pids = [participant_ids[i] for i in val_indices]\n",
        "            train_datasets = [datasets[i] for i in train_indices]\n",
        "            val_datasets = [datasets[i] for i in val_indices]\n",
        "\n",
        "            # Verify no leakage (excluding synthetic participants)\n",
        "            real_train_pids = [pid for pid in train_pids if not pid.startswith('synthetic_')]\n",
        "            real_val_pids = [pid for pid in val_pids if not pid.startswith('synthetic_')]\n",
        "            assert len(set(real_train_pids) & set(real_val_pids)) == 0, f\"Participant leakage in fold {fold_idx}!\"\n",
        "\n",
        "            print(f\"Train: {len(X_train)} sequences ({len(set(real_train_pids))} real participants + {len(synthetic_indices)} synthetic)\")\n",
        "            print(f\"Val: {len(X_val)} sequences, {len(set(real_val_pids))} participants\")\n",
        "\n",
        "            # Create enhanced datasets\n",
        "            train_dataset = EnhancedVRDataset(X_train, y_train, train_pids, train_datasets)\n",
        "            val_dataset = EnhancedVRDataset(X_val, y_val, val_pids, val_datasets)\n",
        "\n",
        "            # Use weighted sampler for balanced training\n",
        "            train_sampler = train_dataset.get_weighted_sampler()\n",
        "            train_loader = DataLoader(\n",
        "                train_dataset,\n",
        "                batch_size=best_params.get('batch_size', 64),\n",
        "                sampler=train_sampler,\n",
        "                num_workers=0\n",
        "            )\n",
        "            val_loader = DataLoader(\n",
        "                val_dataset,\n",
        "                batch_size=best_params.get('batch_size', 64),\n",
        "                shuffle=False,\n",
        "                num_workers=0\n",
        "            )\n",
        "\n",
        "            # Train enhanced model\n",
        "            fold_result = train_enhanced_model(\n",
        "                train_loader=train_loader,\n",
        "                val_loader=val_loader,\n",
        "                input_dim=X.shape[1],\n",
        "                hyperparams=best_params,\n",
        "                num_epochs=num_epochs,\n",
        "                fold_idx=fold_idx\n",
        "            )\n",
        "\n",
        "            fold_results.append(fold_result)\n",
        "\n",
        "        # Aggregate results\n",
        "        print(\"\\n\" + \"=\"*100)\n",
        "        print(\"FINAL RESULTS WITH ADVANCED OVERSAMPLING\")\n",
        "        print(\"=\"*100)\n",
        "\n",
        "        # Calculate comprehensive CV metrics\n",
        "        all_metrics = list(fold_results[0]['metrics'].keys())\n",
        "        cv_metrics = {}\n",
        "\n",
        "        for metric in all_metrics:\n",
        "            values = [fold['metrics'][metric] for fold in fold_results if not np.isnan(fold['metrics'][metric])]\n",
        "            if values:\n",
        "                cv_metrics[f\"{metric}_mean\"] = np.mean(values)\n",
        "                cv_metrics[f\"{metric}_std\"] = np.std(values)\n",
        "            else:\n",
        "                cv_metrics[f\"{metric}_mean\"] = 0.0\n",
        "                cv_metrics[f\"{metric}_std\"] = 0.0\n",
        "\n",
        "        # Print comprehensive results\n",
        "        print(f\"Cross-Validation Results ({n_folds} folds with {oversampling_method} oversampling):\")\n",
        "\n",
        "        # Primary metrics\n",
        "        primary_metrics = ['RMSE', 'MAE', 'R²', 'Lin_CCC']\n",
        "        for metric in primary_metrics:\n",
        "            if f\"{metric}_mean\" in cv_metrics:\n",
        "                mean_val = cv_metrics[f\"{metric}_mean\"]\n",
        "                std_val = cv_metrics[f\"{metric}_std\"]\n",
        "                print(f\"  {metric:>12s}: {mean_val:.4f} ± {std_val:.4f}\")\n",
        "\n",
        "        # Accuracy metrics\n",
        "        print(f\"\\n  Accuracy Metrics:\")\n",
        "        accuracy_metrics = ['Acc@0.5', 'Acc@1.0', 'Acc@1.5', 'Clinical_Accuracy']\n",
        "        for metric in accuracy_metrics:\n",
        "            if f\"{metric}_mean\" in cv_metrics:\n",
        "                mean_val = cv_metrics[f\"{metric}_mean\"]\n",
        "                std_val = cv_metrics[f\"{metric}_std\"]\n",
        "                print(f\"  {metric:>15s}: {mean_val:.4f} ± {std_val:.4f} ({mean_val*100:.1f}%)\")\n",
        "\n",
        "        # Create comprehensive visualizations\n",
        "        print(\"\\nGenerating comprehensive academic visualizations...\")\n",
        "        create_academic_visualizations(fold_results, cv_metrics)\n",
        "        running_example = extract_running_example_after_training(\n",
        "              X=X,\n",
        "              y=y,\n",
        "              participant_ids=participant_ids,\n",
        "              datasets=datasets,\n",
        "              fold_results=fold_results,\n",
        "              target_fms=7.2\n",
        "          )\n",
        "        return {\n",
        "            'cv_metrics': cv_metrics,\n",
        "            'fold_results': fold_results,\n",
        "            'best_hyperparams': best_params,\n",
        "            'processor': processor,\n",
        "            'oversampling_method': oversampling_method,\n",
        "            'running_example': running_example\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Pipeline failed: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZtCY36-hHUGS",
        "outputId": "a62a3789-9cc2-4db1-93a6-4e8ce7718c1d"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Display usage examples first\n",
        "    usage_examples()\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "    # Run main pipeline\n",
        "    try:\n",
        "        results = main()\n",
        "\n",
        "        if results is not None:\n",
        "            print(f\"\\n{'='*80}\")\n",
        "            print(\"PIPELINE COMPLETED SUCCESSFULLY!\")\n",
        "            print(\"All results, visualizations, and reports have been generated.\")\n",
        "            print(f\"{'='*80}\")\n",
        "        else:\n",
        "            print(f\"\\n{'='*80}\")\n",
        "            print(\"PIPELINE FAILED - Please review error messages above\")\n",
        "            print(f\"{'='*80}\")\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n\\nPipeline interrupted by user.\")\n",
        "        print(\"To resume, simply run the script again.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n\\nUnexpected error: {str(e)}\")\n",
        "        print(\"Please review the error details and try again.\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uE4mK6nfZ-7q"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "import matplotlib\n",
        "matplotlib.rcParams.update({'font.size': 12})\n",
        "\n",
        "def save_individual_figures_pdf(fold_results, cv_metrics, output_dir=\"fms_figures\"):\n",
        "    \"\"\"Save each figure as a separate PDF for publication\"\"\"\n",
        "\n",
        "    import os\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Set publication-ready style\n",
        "    plt.rcParams.update({\n",
        "        'figure.figsize': (10, 8),\n",
        "        'font.size': 12,\n",
        "        'axes.titlesize': 14,\n",
        "        'axes.labelsize': 12,\n",
        "        'xtick.labelsize': 11,\n",
        "        'ytick.labelsize': 11,\n",
        "        'legend.fontsize': 11,\n",
        "        'font.family': 'DejaVu Sans',\n",
        "        'axes.linewidth': 1.2,\n",
        "        'grid.alpha': 0.3,\n",
        "        'lines.linewidth': 2.0\n",
        "    })\n",
        "\n",
        "    # Combine all results\n",
        "    all_predictions = np.concatenate([fold['predictions'] for fold in fold_results])\n",
        "    all_targets = np.concatenate([fold['targets'] for fold in fold_results])\n",
        "    residuals = all_predictions - all_targets\n",
        "\n",
        "    return all_predictions, all_targets, residuals, output_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0evexY3xaBxm"
      },
      "outputs": [],
      "source": [
        "def save_regression_plot(all_targets, all_predictions, cv_metrics, output_dir):\n",
        "    \"\"\"Save main regression plot\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "    # Scatter plot\n",
        "    ax.scatter(all_targets, all_predictions, alpha=0.6, s=40, c='steelblue',\n",
        "              edgecolors='navy', linewidth=0.5)\n",
        "\n",
        "    # Perfect prediction line\n",
        "    min_val = min(all_targets.min(), all_predictions.min())\n",
        "    max_val = max(all_targets.max(), all_predictions.max())\n",
        "    ax.plot([min_val, max_val], [min_val, max_val], 'r-', lw=2.5,\n",
        "            label='Perfect Prediction', alpha=0.8)\n",
        "\n",
        "    # Regression line\n",
        "    z = np.polyfit(all_targets, all_predictions, 1)\n",
        "    p = np.poly1d(z)\n",
        "    ax.plot(all_targets, p(all_targets), 'g--', lw=2.5,\n",
        "            label=f'Regression Line (y={z[0]:.2f}x+{z[1]:.2f})', alpha=0.8)\n",
        "\n",
        "    ax.set_xlabel('True FMS Scores', fontsize=14, fontweight='bold')\n",
        "    ax.set_ylabel('Predicted FMS Scores', fontsize=14, fontweight='bold')\n",
        "    ax.set_title('FMS Prediction Performance', fontsize=16, fontweight='bold', pad=20)\n",
        "    ax.legend(fontsize=12, loc='lower right')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    # Statistics box\n",
        "    stats_text = (f'RMSE = {cv_metrics[\"RMSE_mean\"]:.3f}\\n'\n",
        "                 f'MAE = {cv_metrics[\"MAE_mean\"]:.3f}\\n'\n",
        "                 f'R² = {cv_metrics[\"R²_mean\"]:.3f}\\n'\n",
        "                 f'Lin CCC = {cv_metrics[\"Lin_CCC_mean\"]:.3f}')\n",
        "    ax.text(0.05, 0.95, stats_text, transform=ax.transAxes, fontsize=12,\n",
        "            verticalalignment='top', bbox=dict(boxstyle='round,pad=0.5',\n",
        "            facecolor='white', edgecolor='black', alpha=0.9))\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{output_dir}/01_regression_plot.pdf', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def save_bland_altman_plot(all_targets, all_predictions, cv_metrics, output_dir):\n",
        "    \"\"\"Save Bland-Altman plot\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "    mean_values = (all_targets + all_predictions) / 2\n",
        "    differences = all_predictions - all_targets\n",
        "\n",
        "    ax.scatter(mean_values, differences, alpha=0.6, s=40, c='lightcoral',\n",
        "              edgecolors='darkred', linewidth=0.5)\n",
        "\n",
        "    # Mean difference line\n",
        "    mean_diff = np.mean(differences)\n",
        "    ax.axhline(y=mean_diff, color='blue', linestyle='-', lw=2.5,\n",
        "               label=f'Mean Bias = {mean_diff:.3f}')\n",
        "\n",
        "    # Limits of agreement\n",
        "    std_diff = np.std(differences)\n",
        "    upper_loa = mean_diff + 1.96 * std_diff\n",
        "    lower_loa = mean_diff - 1.96 * std_diff\n",
        "\n",
        "    ax.axhline(y=upper_loa, color='red', linestyle='--', lw=2.5,\n",
        "               label=f'Upper LoA = {upper_loa:.3f}')\n",
        "    ax.axhline(y=lower_loa, color='red', linestyle='--', lw=2.5,\n",
        "               label=f'Lower LoA = {lower_loa:.3f}')\n",
        "\n",
        "    ax.set_xlabel('Mean of True and Predicted FMS', fontsize=14, fontweight='bold')\n",
        "    ax.set_ylabel('Difference (Predicted - True)', fontsize=14, fontweight='bold')\n",
        "    ax.set_title('Bland-Altman Agreement Plot', fontsize=16, fontweight='bold', pad=20)\n",
        "    ax.legend(fontsize=12)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{output_dir}/02_bland_altman_plot.pdf', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def save_residuals_plot(all_predictions, residuals, output_dir):\n",
        "    \"\"\"Save residuals plot\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "    ax.scatter(all_predictions, residuals, alpha=0.6, s=40, c='lightgreen',\n",
        "              edgecolors='darkgreen', linewidth=0.5)\n",
        "    ax.axhline(y=0, color='red', linestyle='--', lw=2.5, alpha=0.8)\n",
        "\n",
        "    ax.set_xlabel('Predicted FMS Scores', fontsize=14, fontweight='bold')\n",
        "    ax.set_ylabel('Residuals (Predicted - True)', fontsize=14, fontweight='bold')\n",
        "    ax.set_title('Residuals vs Fitted Values', fontsize=16, fontweight='bold', pad=20)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{output_dir}/03_residuals_plot.pdf', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def save_qq_plot(residuals, output_dir):\n",
        "    \"\"\"Save Q-Q plot\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "    from scipy import stats\n",
        "    stats.probplot(residuals, dist=\"norm\", plot=ax)\n",
        "    ax.set_title('Q-Q Plot of Residuals', fontsize=16, fontweight='bold', pad=20)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    # Enhance axis labels\n",
        "    ax.set_xlabel('Theoretical Quantiles', fontsize=14, fontweight='bold')\n",
        "    ax.set_ylabel('Sample Quantiles', fontsize=14, fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{output_dir}/04_qq_plot.pdf', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def save_accuracy_metrics_plot(cv_metrics, output_dir):\n",
        "    \"\"\"Save accuracy metrics bar chart\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "    accuracy_metrics = ['Acc@0.25', 'Acc@0.5', 'Acc@0.75', 'Acc@1.0',\n",
        "                       'Acc@1.25', 'Acc@1.5', 'Acc@2.0']\n",
        "    accuracy_values = [cv_metrics[f'{metric}_mean'] for metric in accuracy_metrics]\n",
        "    accuracy_stds = [cv_metrics[f'{metric}_std'] for metric in accuracy_metrics]\n",
        "\n",
        "    colors = plt.cm.RdYlBu_r(np.linspace(0.2, 0.8, len(accuracy_metrics)))\n",
        "    x_pos = np.arange(len(accuracy_metrics))\n",
        "\n",
        "    bars = ax.bar(x_pos, accuracy_values, yerr=accuracy_stds, capsize=7,\n",
        "                 alpha=0.8, color=colors, edgecolor='black', linewidth=1.5)\n",
        "\n",
        "    ax.set_xlabel('Tolerance Levels (FMS Points)', fontsize=14, fontweight='bold')\n",
        "    ax.set_ylabel('Accuracy', fontsize=14, fontweight='bold')\n",
        "    ax.set_title('Accuracy at Different Tolerance Levels', fontsize=16, fontweight='bold', pad=20)\n",
        "    ax.set_xticks(x_pos)\n",
        "    ax.set_xticklabels([m.replace('Acc@', '±') for m in accuracy_metrics])\n",
        "    ax.set_ylim(0, 1.05)\n",
        "    ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for i, (bar, val) in enumerate(zip(bars, accuracy_values)):\n",
        "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
        "                f'{val:.3f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{output_dir}/05_accuracy_metrics.pdf', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def save_confusion_matrix_plot(all_targets, all_predictions, output_dir):\n",
        "    \"\"\"Save functional class confusion matrix\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "    # Define functional classes\n",
        "    class_bounds = [0, 3.5, 6.5, 10.1]\n",
        "    class_labels = ['Severe (1-3)', 'Moderate (4-6)', 'Mild (7-10)']\n",
        "\n",
        "    true_classes = np.digitize(all_targets, class_bounds) - 1\n",
        "    pred_classes = np.digitize(all_predictions, class_bounds) - 1\n",
        "\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    cm = confusion_matrix(true_classes, pred_classes, labels=[0, 1, 2])\n",
        "\n",
        "    # Create heatmap\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap='Blues')\n",
        "    ax.figure.colorbar(im, ax=ax, shrink=0.8)\n",
        "\n",
        "    # Add text annotations\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], 'd'),\n",
        "                   ha=\"center\", va=\"center\", fontsize=14, fontweight='bold',\n",
        "                   color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    ax.set_xlabel('Predicted Functional Class', fontsize=14, fontweight='bold')\n",
        "    ax.set_ylabel('True Functional Class', fontsize=14, fontweight='bold')\n",
        "    ax.set_title('Functional Class Confusion Matrix', fontsize=16, fontweight='bold', pad=20)\n",
        "    ax.set_xticks(np.arange(len(class_labels)))\n",
        "    ax.set_yticks(np.arange(len(class_labels)))\n",
        "    ax.set_xticklabels(class_labels)\n",
        "    ax.set_yticklabels(class_labels)\n",
        "\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{output_dir}/06_confusion_matrix.pdf', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def save_error_distribution_plot(all_targets, residuals, output_dir):\n",
        "    \"\"\"Save error distribution by FMS ranges\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "    fms_ranges = [(1, 3), (3, 5), (5, 7), (7, 10)]\n",
        "    range_errors = []\n",
        "    range_labels = []\n",
        "    range_colors = ['#ff9999', '#66b3ff', '#99ff99', '#ffcc99']\n",
        "\n",
        "    for low, high in fms_ranges:\n",
        "        mask = ((all_targets >= low) & (all_targets < high)) if high < 10 else ((all_targets >= low) & (all_targets <= high))\n",
        "        if np.any(mask):\n",
        "            range_residuals = np.abs(residuals[mask])\n",
        "            range_errors.append(range_residuals)\n",
        "            range_labels.append(f'{low}-{high}')\n",
        "\n",
        "    if range_errors:\n",
        "        box_plot = ax.boxplot(range_errors, labels=range_labels, patch_artist=True, widths=0.6)\n",
        "        for patch, color in zip(box_plot['boxes'], range_colors[:len(range_errors)]):\n",
        "            patch.set_facecolor(color)\n",
        "            patch.set_alpha(0.8)\n",
        "            patch.set_linewidth(1.5)\n",
        "\n",
        "    ax.set_xlabel('FMS Score Range', fontsize=14, fontweight='bold')\n",
        "    ax.set_ylabel('Absolute Error', fontsize=14, fontweight='bold')\n",
        "    ax.set_title('Error Distribution by FMS Range', fontsize=16, fontweight='bold', pad=20)\n",
        "    ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{output_dir}/07_error_distribution.pdf', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def save_training_progress_plot(fold_results, output_dir):\n",
        "    \"\"\"Save training progress plot\"\"\"\n",
        "    fig, ax1 = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "    # Align training histories\n",
        "    min_length = min(len(fold['train_losses']) for fold in fold_results if fold['train_losses'])\n",
        "    if min_length > 0:\n",
        "        train_losses_aligned = [fold['train_losses'][:min_length] for fold in fold_results if fold['train_losses']]\n",
        "        val_rmses_aligned = [fold['val_rmses'][:min_length] for fold in fold_results if fold['val_rmses']]\n",
        "\n",
        "        if train_losses_aligned and val_rmses_aligned:\n",
        "            avg_train_loss = np.mean(train_losses_aligned, axis=0)\n",
        "            avg_val_rmse = np.mean(val_rmses_aligned, axis=0)\n",
        "            std_train_loss = np.std(train_losses_aligned, axis=0)\n",
        "            std_val_rmse = np.std(val_rmses_aligned, axis=0)\n",
        "\n",
        "            epochs = range(1, len(avg_train_loss) + 1)\n",
        "\n",
        "            # Training loss\n",
        "            color1 = 'tab:blue'\n",
        "            ax1.set_xlabel('Epoch', fontsize=14, fontweight='bold')\n",
        "            ax1.set_ylabel('Training Loss', color=color1, fontsize=14, fontweight='bold')\n",
        "            line1 = ax1.plot(epochs, avg_train_loss, color=color1, linewidth=3, label='Training Loss')\n",
        "            ax1.fill_between(epochs, avg_train_loss - std_train_loss, avg_train_loss + std_train_loss,\n",
        "                           alpha=0.3, color=color1)\n",
        "            ax1.tick_params(axis='y', labelcolor=color1)\n",
        "            ax1.grid(True, alpha=0.3)\n",
        "\n",
        "            # Validation RMSE\n",
        "            ax2 = ax1.twinx()\n",
        "            color2 = 'tab:red'\n",
        "            ax2.set_ylabel('Validation RMSE', color=color2, fontsize=14, fontweight='bold')\n",
        "            line2 = ax2.plot(epochs, avg_val_rmse, color=color2, linewidth=3, label='Validation RMSE')\n",
        "            ax2.fill_between(epochs, avg_val_rmse - std_val_rmse, avg_val_rmse + std_val_rmse,\n",
        "                           alpha=0.3, color=color2)\n",
        "            ax2.tick_params(axis='y', labelcolor=color2)\n",
        "\n",
        "            # Combined legend\n",
        "            lines = line1 + line2\n",
        "            labels = [l.get_label() for l in lines]\n",
        "            ax1.legend(lines, labels, loc='upper right', fontsize=12)\n",
        "\n",
        "            ax1.set_title('Training Progress (Mean ± SD)', fontsize=16, fontweight='bold', pad=20)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{output_dir}/08_training_progress.pdf', dpi=300, bbox_inches='tight')\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZiY2ut3jHau"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.stats import gaussian_kde\n",
        "\n",
        "def save_regression_plot(all_targets, all_predictions, cv_metrics, output_dir):\n",
        "    \"\"\"Save main regression plot (original style)\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "    # Scatter plot\n",
        "    ax.scatter(all_targets, all_predictions, alpha=0.6, s=40, c='steelblue',\n",
        "              edgecolors='navy', linewidth=0.5)\n",
        "\n",
        "    # Perfect prediction line\n",
        "    min_val = min(all_targets.min(), all_predictions.min())\n",
        "    max_val = max(all_targets.max(), all_predictions.max())\n",
        "    ax.plot([min_val, max_val], [min_val, max_val], 'r-', lw=2.5,\n",
        "            label='Perfect Prediction', alpha=0.8)\n",
        "\n",
        "    # Regression line\n",
        "    z = np.polyfit(all_targets, all_predictions, 1)\n",
        "    p = np.poly1d(z)\n",
        "    ax.plot(all_targets, p(all_targets), 'g--', lw=2.5,\n",
        "            label=f'Regression Line (y={z[0]:.2f}x+{z[1]:.2f})', alpha=0.8)\n",
        "\n",
        "    ax.set_xlabel('True FMS Scores', fontsize=14, fontweight='bold')\n",
        "    ax.set_ylabel('Predicted FMS Scores', fontsize=14, fontweight='bold')\n",
        "    ax.set_title('FMS Prediction Performance', fontsize=16, fontweight='bold', pad=20)\n",
        "    ax.legend(fontsize=12, loc='lower right')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    # Statistics box\n",
        "    stats_text = (f'RMSE = {cv_metrics[\"RMSE_mean\"]:.3f}\\n'\n",
        "                 f'MAE = {cv_metrics[\"MAE_mean\"]:.3f}\\n'\n",
        "                 f'R² = {cv_metrics[\"R²_mean\"]:.3f}\\n'\n",
        "                 f'Lin CCC = {cv_metrics[\"Lin_CCC_mean\"]:.3f}')\n",
        "    ax.text(0.05, 0.95, stats_text, transform=ax.transAxes, fontsize=12,\n",
        "            verticalalignment='top', bbox=dict(boxstyle='round,pad=0.5',\n",
        "            facecolor='white', edgecolor='black', alpha=0.9))\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{output_dir}/01_regression_plot.pdf', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def save_density_plot(all_targets, all_predictions, cv_metrics, output_dir):\n",
        "    \"\"\"Save density plot showing concentration around regression line\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "    # Create hexbin plot to show density\n",
        "    hb = ax.hexbin(all_targets, all_predictions, gridsize=25, cmap='viridis',\n",
        "                   mincnt=1, alpha=0.8)\n",
        "\n",
        "    # Add colorbar\n",
        "    cbar = plt.colorbar(hb, ax=ax)\n",
        "    cbar.set_label('Number of Points', fontsize=12, fontweight='bold')\n",
        "\n",
        "    # Perfect prediction line\n",
        "    min_val = min(all_targets.min(), all_predictions.min())\n",
        "    max_val = max(all_targets.max(), all_predictions.max())\n",
        "    ax.plot([min_val, max_val], [min_val, max_val], 'r-', lw=3,\n",
        "            label='Perfect Prediction', alpha=0.9, zorder=10)\n",
        "\n",
        "    # Regression line\n",
        "    z = np.polyfit(all_targets, all_predictions, 1)\n",
        "    p = np.poly1d(z)\n",
        "\n",
        "    ax.set_xlabel('True FMS Scores', fontsize=14, fontweight='bold')\n",
        "    ax.set_ylabel('Predicted FMS Scores', fontsize=14, fontweight='bold')\n",
        "    ax.set_title('Point Density Around Regression Line', fontsize=16, fontweight='bold', pad=20)\n",
        "    ax.legend(fontsize=12, loc='lower right')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{output_dir}/02_density_plot.pdf', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def save_residuals_plot(all_targets, all_predictions, output_dir):\n",
        "    \"\"\"Save residuals distribution plot\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    # Calculate residuals\n",
        "    residuals = all_predictions - all_targets\n",
        "\n",
        "    # Histogram of residuals\n",
        "    ax.hist(residuals, bins=30, density=True, alpha=0.7,\n",
        "            color='lightblue', edgecolor='navy', linewidth=0.5)\n",
        "\n",
        "    # Overlay normal distribution curve\n",
        "    mu, sigma = np.mean(residuals), np.std(residuals)\n",
        "    x_norm = np.linspace(residuals.min(), residuals.max(), 100)\n",
        "    y_norm = ((1/np.sqrt(2*np.pi*sigma**2)) *\n",
        "              np.exp(-0.5*((x_norm-mu)/sigma)**2))\n",
        "    ax.plot(x_norm, y_norm, 'darkred', lw=3,\n",
        "             label=f'Normal Distribution (μ={mu:.3f}, σ={sigma:.3f})')\n",
        "\n",
        "    # Add vertical line at zero\n",
        "    ax.axvline(x=0, color='red', linestyle='--', lw=2,\n",
        "               label='Perfect Prediction (residual=0)', alpha=0.8)\n",
        "\n",
        "    # Add vertical line at mean\n",
        "    mean_residual = np.mean(residuals)\n",
        "    ax.axvline(x=mean_residual, color='orange', linestyle='-', lw=2,\n",
        "               label=f'Mean Residual ({mean_residual:.3f})', alpha=0.8)\n",
        "\n",
        "    ax.set_xlabel('Residuals (Predicted - True)', fontsize=18, fontweight='bold')\n",
        "    ax.set_ylabel('Density', fontsize=18, fontweight='bold')\n",
        "    ax.set_title('Distribution of Residuals', fontsize=18, fontweight='bold', pad=20)\n",
        "    ax.legend(fontsize=16)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{output_dir}/03_residuals_plot.pdf', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# Usage example:\n",
        "# save_regression_plot(all_targets, all_predictions, cv_metrics, output_dir)\n",
        "# save_density_plot(all_targets, all_predictions, cv_metrics, output_dir)\n",
        "# save_residuals_plot(all_targets, all_predictions, output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mX9Xyp-9aDpt"
      },
      "outputs": [],
      "source": [
        "def save_all_publication_figures(fold_results, cv_metrics, output_dir=\"fms_publication_figures\"):\n",
        "    \"\"\"Save all figures as separate PDFs for publication\"\"\"\n",
        "\n",
        "    print(f\"\\nSaving publication-ready figures to: {output_dir}/\")\n",
        "\n",
        "    # Prepare data and create output directory\n",
        "    all_predictions, all_targets, residuals, output_dir = save_individual_figures_pdf(\n",
        "        fold_results, cv_metrics, output_dir)\n",
        "\n",
        "    # Save all individual figures\n",
        "    save_regression_plot(all_targets, all_predictions, cv_metrics, output_dir)\n",
        "    save_bland_altman_plot(all_targets, all_predictions, cv_metrics, output_dir)\n",
        "    save_residuals_plot(all_predictions, residuals, output_dir)\n",
        "    save_qq_plot(residuals, output_dir)\n",
        "    save_accuracy_metrics_plot(cv_metrics, output_dir)\n",
        "    save_confusion_matrix_plot(all_targets, all_predictions, output_dir)\n",
        "    save_error_distribution_plot(all_targets, residuals, output_dir)\n",
        "    save_training_progress_plot(fold_results, output_dir)\n",
        "    save_regression_plot(all_targets, all_predictions, cv_metrics, output_dir)\n",
        "    save_density_plot(all_targets, all_predictions, cv_metrics, output_dir)\n",
        "    save_residuals_plot(all_targets, all_predictions, output_dir)\n",
        "\n",
        "    # Reset matplotlib parameters\n",
        "    plt.rcParams.update(plt.rcParamsDefault)\n",
        "\n",
        "    print(f\"✓ Saved 8 publication-ready figures as individual PDFs\")\n",
        "    print(f\"✓ All figures saved with 300 DPI resolution\")\n",
        "    print(f\"✓ Text sized appropriately for academic papers\")\n",
        "\n",
        "    return output_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOz9M2UtaI-w",
        "outputId": "e389bd17-89e4-46d1-b874-3412d78f77a1"
      },
      "outputs": [],
      "source": [
        "# Add this at the end of your run_enhanced_pipeline function or after getting results:\n",
        "if results is not None:\n",
        "    # Save individual publication figures\n",
        "    figure_dir = save_all_publication_figures(results['fold_results'], results['cv_metrics'])\n",
        "    print(f\"\\nPublication figures available in: {figure_dir}/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "FNyGks9PtJmE",
        "outputId": "aeb65234-04be-4a7c-d865-423d3508e5e6"
      },
      "outputs": [],
      "source": [
        "validation_dataset"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
